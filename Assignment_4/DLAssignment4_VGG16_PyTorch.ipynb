{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DLAssignment4_VGG16_PyTorch.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/akshaya-nagarajan/DeepLearningProjects/blob/master/Assignment_4/DLAssignment4_VGG16_PyTorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AYHuM6rdve_i",
        "colab_type": "text"
      },
      "source": [
        "## Import Required Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SObiRKgkQaRx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.optim.lr_scheduler import _LRScheduler\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.nn import CrossEntropyLoss\n",
        "from torch.optim import SGD\n",
        "import numpy as np\n",
        "from torch.autograd import Variable"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WvM4853sviSg",
        "colab_type": "text"
      },
      "source": [
        "## Define the model architecture in VGG16 class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TpHKV7OgFgvy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cfg = {    \n",
        "    'D' : [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 'M', 512, 512, 512, 'M', 512, 512, 512, 'M']\n",
        "}\n",
        "\n",
        "class VGG(nn.Module):\n",
        "    def __init__(self, features, num_class=100):\n",
        "        super().__init__()\n",
        "        self.features = features\n",
        "\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(512, 4096),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(4096, 4096),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(4096, num_class)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        output = self.features(x)\n",
        "        output = output.view(output.size()[0], -1)\n",
        "        output = self.classifier(output)\n",
        "    \n",
        "        return output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d2JmNHn-voHR",
        "colab_type": "text"
      },
      "source": [
        "## Create additional layers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eg9We_boQB-r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def make_layers(cfg, batch_norm=False):\n",
        "    layers = []\n",
        "\n",
        "    input_channel = 3\n",
        "    for l in cfg:\n",
        "        if l == 'M':\n",
        "            layers += [nn.MaxPool2d(kernel_size=2, stride=2)]\n",
        "            continue\n",
        "\n",
        "        layers += [nn.Conv2d(input_channel, l, kernel_size=3, padding=1)]\n",
        "\n",
        "        if batch_norm:\n",
        "            layers += [nn.BatchNorm2d(l)]\n",
        "        \n",
        "        layers += [nn.ReLU(inplace=True)]\n",
        "        input_channel = l\n",
        "    \n",
        "    return nn.Sequential(*layers)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zqs5vJ0LvtS6",
        "colab_type": "text"
      },
      "source": [
        "## Create the VGG16 Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gBrqB1uIQeuh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def vgg16_bn():\n",
        "    return VGG(make_layers(cfg['D'], batch_norm=True))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vsGtcwOjvw5l",
        "colab_type": "text"
      },
      "source": [
        "## Get CIFAR 100 Train dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OL_pzdWTTDtM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_training_dataloader(batch_size=16, num_workers=2, shuffle=True):\n",
        "    transform_train = transforms.Compose([\n",
        "        #transforms.ToPILImage(),\n",
        "        transforms.RandomCrop(32, padding=4),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.RandomRotation(15),\n",
        "        transforms.ToTensor()\n",
        "    ])\n",
        "    #cifar100_training = CIFAR100Train(path, transform=transform_train)\n",
        "    cifar100_training = torchvision.datasets.CIFAR100(root='./data', train=True, download=True, transform=transform_train)\n",
        "    cifar100_training_loader = DataLoader(\n",
        "        cifar100_training, shuffle=shuffle, num_workers=num_workers, batch_size=batch_size)\n",
        "\n",
        "    return cifar100_training_loader"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XnNL8MfYv1QJ",
        "colab_type": "text"
      },
      "source": [
        "## Get  CIFAR 100 Test dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2v1HCJ5hacY3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_test_dataloader(batch_size=16, num_workers=2, shuffle=True):\n",
        "    transform_test = transforms.Compose([\n",
        "        transforms.ToTensor()\n",
        "    ])\n",
        "    #cifar100_test = CIFAR100Test(path, transform=transform_test)\n",
        "    cifar100_test = torchvision.datasets.CIFAR100(root='./data', train=False, download=True, transform=transform_test)\n",
        "    cifar100_test_loader = DataLoader(\n",
        "        cifar100_test, shuffle=shuffle, num_workers=num_workers, batch_size=batch_size)\n",
        "\n",
        "    return cifar100_test_loader"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0wtb2-yUv4UR",
        "colab_type": "text"
      },
      "source": [
        "## Download CIFAR 100 Train dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "61D4cKP_QgJE",
        "colab_type": "code",
        "outputId": "9de307d0-e7a2-487b-add1-f3581bc3a046",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "trainloader = get_training_dataloader(num_workers=2, batch_size=128)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tsX19fRUv7aY",
        "colab_type": "text"
      },
      "source": [
        "## Download CIFAR 100 Test dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4zlvlMfRaOUZ",
        "colab_type": "code",
        "outputId": "8e94d83f-917b-4cb7-bee8-dd493666cf8e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "testloader = get_test_dataloader(num_workers=2, batch_size=128)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lYCzDeRgv9bu",
        "colab_type": "text"
      },
      "source": [
        "## Get the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bkIe3uqmagc_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "net = vgg16_bn()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xvjUDKAWwAzY",
        "colab_type": "text"
      },
      "source": [
        "## Check if the Code is running on GPU if available"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t8UcKCLJty8z",
        "colab_type": "code",
        "outputId": "f1059a92-cdc4-400d-9ee2-7d1376809443",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q8a1se-VwKkM",
        "colab_type": "text"
      },
      "source": [
        "## Convert parameters and buffers to CUDA tensors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wWFxadxfqEoi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "use_gpu = torch.cuda.is_available()\n",
        "if use_gpu:\n",
        "    net = net.to(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mQX2ffhdwWAD",
        "colab_type": "text"
      },
      "source": [
        "## Initialize Optimizers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "02N-JjUhqSFf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cv6DS5YhwZJW",
        "colab_type": "text"
      },
      "source": [
        "## Train the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z8A9AssDqZXQ",
        "colab_type": "code",
        "outputId": "12c6c36a-528a-4589-85d4-b3defff9bf84",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "for epoch in range(2):  # loop over the dataset multiple times\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(trainloader, 0):\n",
        "        # get the inputs; data is a list of [inputs, labels]\n",
        "        #inputs, labels = data\n",
        "        inputs, labels = data[0].to(device), data[1].to(device)\n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # forward + backward + optimize\n",
        "        outputs = net(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # print statistics\n",
        "        running_loss += loss.item()\n",
        "        if i % 2000 == 1999:    # print every 2000 mini-batches\n",
        "            print('[%d, %5d] loss: %.3f' %\n",
        "                  (epoch + 1, i + 1, running_loss / 2000))\n",
        "            running_loss = 0.0\n",
        "\n",
        "print('Finished Training')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Finished Training\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gpzgDjhywbRv",
        "colab_type": "text"
      },
      "source": [
        "## Save the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IW8lQ966r4_m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "PATH = './cifar_net.pth'\n",
        "torch.save(net.state_dict(), PATH)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WYmc8xwPwesl",
        "colab_type": "text"
      },
      "source": [
        "## Get the Actual Values"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mjy8TSNIrNeq",
        "colab_type": "code",
        "outputId": "5786dffb-1a25-4fd7-f8c1-3425f5453221",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "dataiter = iter(testloader)\n",
        "#images, labels = dataiter.next()\n",
        "images, labels = dataiter.next()\n",
        "# print images\n",
        "#imshow(torchvision.utils.make_grid(images))\n",
        "print('GroundTruth: ', ' '.join('%5s' % labels[j] for j in range(4)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "GroundTruth:  tensor(44) tensor(66) tensor(11) tensor(89)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vf4qdKbEtEdv",
        "colab_type": "code",
        "outputId": "006c7135-b1fd-4d9e-bfb0-c8025d468752",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "net.load_state_dict(torch.load(PATH))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_R_8PRHjwjEO",
        "colab_type": "text"
      },
      "source": [
        "## Convert to CUDA Tensors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mqdl7nOetJp0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "outputs = net(images.to(device))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x36jWFd4wnwn",
        "colab_type": "text"
      },
      "source": [
        "## Get the predicted Labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bXfVShjut1C4",
        "colab_type": "code",
        "outputId": "be95959b-9b18-4aa6-f9d1-52568a7d5bac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "_, predicted = torch.max(outputs, 1)\n",
        "print('Predicted: ', (predicted[j] for j in range(4)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Predicted:  <generator object <genexpr> at 0x7fd7d66ecf68>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YpGOMllmwqUX",
        "colab_type": "text"
      },
      "source": [
        "## Get the Accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LjI0q0qhuhHN",
        "colab_type": "code",
        "outputId": "251fd7d1-b3fc-4c63-d111-7007c79f5c46",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for data in testloader:\n",
        "        #images, labels = data\n",
        "        images, labels = data[0].to(device), data[1].to(device)\n",
        "        outputs = net(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
        "    100 * correct / total))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the 10000 test images: 12 %\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}