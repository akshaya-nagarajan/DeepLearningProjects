{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DLProjectTransferLearningModelInceptionModelMultiClass.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/akshaya-nagarajan/DeepLearningProjects/blob/master/Project/DLProjectTransferLearningModelInceptionModelMultiClass.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sKB2bZU0FEyj",
        "colab_type": "text"
      },
      "source": [
        "## Mounting the Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vL6HRkt5w3sq",
        "colab_type": "code",
        "outputId": "8f3cf3bc-eae8-47db-aaec-d40088f2b75d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive/', force_remount=True)\n",
        "root_dir = \"/content/gdrive/My Drive/Deep Learning project/\"\n",
        "image_dir = root_dir + 'Images/'"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bf5-lQg-FHWW",
        "colab_type": "text"
      },
      "source": [
        "## To determine which version of TensorFlow being used"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qt4QFYdGZP4g",
        "colab_type": "code",
        "outputId": "ec9ea6f0-4713-451c-fd1d-06a5f0d2f5b7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        }
      },
      "source": [
        "# To determine which version you're using:\n",
        "!pip show tensorflow"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Name: tensorflow\n",
            "Version: 2.2.0\n",
            "Summary: TensorFlow is an open source machine learning framework for everyone.\n",
            "Home-page: https://www.tensorflow.org/\n",
            "Author: Google Inc.\n",
            "Author-email: packages@tensorflow.org\n",
            "License: Apache 2.0\n",
            "Location: /usr/local/lib/python3.6/dist-packages\n",
            "Requires: absl-py, termcolor, protobuf, grpcio, astunparse, google-pasta, six, tensorboard, tensorflow-estimator, h5py, wrapt, wheel, scipy, keras-preprocessing, gast, opt-einsum, numpy\n",
            "Required-by: fancyimpute\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dkDtP-VnFLH2",
        "colab_type": "text"
      },
      "source": [
        "## Install required Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "prqeDU_-QkWs",
        "colab_type": "code",
        "outputId": "8b8680fc-307e-4b95-e492-8bbe5e614809",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "import tensorflow\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img, save_img\n",
        "from tensorflow.keras.layers import Input, Lambda, Dense, Flatten, GlobalAveragePooling2D\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.applications.vgg16 import VGG16\n",
        "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.utils import plot_model\n",
        "from tensorflow.keras.applications.inception_v3 import InceptionV3, preprocess_input\n",
        "\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "from tensorflow.keras.callbacks import TensorBoard\n",
        "import time\n",
        "import datetime\n",
        "\n",
        "# Load the TensorBoard notebook extension\n",
        "%load_ext tensorboard \n",
        "\n",
        "from glob import glob\n",
        "import numpy as np\n",
        "from numpy import expand_dims\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
        "\n",
        "import seaborn as sns\n",
        "sns.set(style=\"white\")\n",
        "sns.set(style=\"whitegrid\", color_codes=True)\n",
        "\n",
        "import os\n",
        "from shutil import copy\n",
        "from shutil import copytree, rmtree\n",
        "import argparse\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "plt.style.use(\"ggplot\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pvq1fiDBn5O7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import tensorflow.compat.v1 as tf\n",
        "# #To make tf 2.0 compatible with tf1.0 code, we disable the tf2.0 functionalities\n",
        "# tf.disable_eager_execution()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5qgMDKm3FSL9",
        "colab_type": "text"
      },
      "source": [
        "## Detect hardware and return appropriate distribution strategies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WNIrL4CoFUxs",
        "colab_type": "code",
        "outputId": "cbe3d5a7-5321-49a8-a26e-dd2683492b4d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "try:\n",
        "    # TPU detection. No parameters necessary if TPU_NAME environment variable is set. On Kaggle this is always the case.\n",
        "    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
        "    print('Running on TPU ', tpu.master())\n",
        "except ValueError:\n",
        "    tpu = None\n",
        "\n",
        "if tpu:\n",
        "    tf.config.experimental_connect_to_cluster(tpu)\n",
        "    tf.tpu.experimental.initialize_tpu_system(tpu)\n",
        "    strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
        "else:\n",
        "    # default distribution strategy in Tensorflow. Works on CPU and single GPU.\n",
        "    strategy = tf.distribute.get_strategy()\n",
        "\n",
        "print(\"REPLICAS: \", strategy.num_replicas_in_sync)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "REPLICAS:  1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MDgF8e3WFZlV",
        "colab_type": "text"
      },
      "source": [
        "## This is the TPU initialization code that has to be at the beginning.(Commented)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HgT-7uCkjbe4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu='grpc://' + os.environ['COLAB_TPU_ADDR'])\n",
        "# tf.config.experimental_connect_to_cluster(resolver)\n",
        "# # This is the TPU initialization code that has to be at the beginning.\n",
        "# tf.tpu.experimental.initialize_tpu_system(resolver)\n",
        "# strategy = tf.distribute.experimental.TPUStrategy(resolver)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZCKoAj7rFb1R",
        "colab_type": "text"
      },
      "source": [
        "## Displaying the Train Folder in the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bdIYsPp-dhaO",
        "colab_type": "code",
        "outputId": "9672e25a-1e5c-4868-9198-c33ec30a806a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        }
      },
      "source": [
        "train_folders = glob(image_dir+'Split/Train/*')\n",
        "# Lists all the folders in train set\n",
        "train_folders"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/content/gdrive/My Drive/Deep Learning project/Images/Split/Train/LowLunge',\n",
              " '/content/gdrive/My Drive/Deep Learning project/Images/Split/Train/DownwardFacingDog',\n",
              " '/content/gdrive/My Drive/Deep Learning project/Images/Split/Train/TreePose',\n",
              " '/content/gdrive/My Drive/Deep Learning project/Images/Split/Train/WarriorPose',\n",
              " '/content/gdrive/My Drive/Deep Learning project/Images/Split/Train/Planks',\n",
              " '/content/gdrive/My Drive/Deep Learning project/Images/Split/Train/ReversePlanks',\n",
              " '/content/gdrive/My Drive/Deep Learning project/Images/Split/Train/SidePlanks',\n",
              " '/content/gdrive/My Drive/Deep Learning project/Images/Split/Train/SeatedForwardBend',\n",
              " '/content/gdrive/My Drive/Deep Learning project/Images/Split/Train/TrianglePose']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EiuqqB2fFhaF",
        "colab_type": "text"
      },
      "source": [
        "## Displaying the Test Folder in the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gkf84zU1d3Iw",
        "colab_type": "code",
        "outputId": "376d90f3-08ce-4258-dd38-0fe2518982c6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        }
      },
      "source": [
        "test_folders = glob(image_dir+'Split/Test/*')\n",
        "# Lists all the folders in test set\n",
        "test_folders"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/content/gdrive/My Drive/Deep Learning project/Images/Split/Test/LowLunge',\n",
              " '/content/gdrive/My Drive/Deep Learning project/Images/Split/Test/DownwardFacingDog',\n",
              " '/content/gdrive/My Drive/Deep Learning project/Images/Split/Test/TreePose',\n",
              " '/content/gdrive/My Drive/Deep Learning project/Images/Split/Test/WarriorPose',\n",
              " '/content/gdrive/My Drive/Deep Learning project/Images/Split/Test/Planks',\n",
              " '/content/gdrive/My Drive/Deep Learning project/Images/Split/Test/ReversePlanks',\n",
              " '/content/gdrive/My Drive/Deep Learning project/Images/Split/Test/SidePlanks',\n",
              " '/content/gdrive/My Drive/Deep Learning project/Images/Split/Test/SeatedForwardBend',\n",
              " '/content/gdrive/My Drive/Deep Learning project/Images/Split/Test/TrianglePose']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "niIZ0CVzFrEG",
        "colab_type": "text"
      },
      "source": [
        "## Specifying the Train-Test paths "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k5jHoTGZd_e1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Actual train and test paths\n",
        "train_path = image_dir+'Split/Train'\n",
        "test_path = image_dir+'Split/Test'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7kLlvjZ4FyaP",
        "colab_type": "text"
      },
      "source": [
        "## Creating a Mini Dataset for Testing Purposes and for other Multiple runs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HaUnlfhXCSPF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_dataset_mini(img_list, source, destination):\n",
        "  if os.path.exists(destination):\n",
        "    # removing Mini dataset folder (if it already exists) folders, so that we will have only the classes that we want\n",
        "    rmtree(destination) \n",
        "  # Make the destination directories\n",
        "  os.makedirs(destination)\n",
        "  # Iterate through each image specified in the image list and get all the images from that folder only\n",
        "  \n",
        "  for img_item in img_list :\n",
        "    print(\"Copying images into\",img_item)\n",
        "    # Copy the images from source to destination\n",
        "    copytree(os.path.join(source, img_item), os.path.join(destination, img_item))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q4ws3uPpF5Gn",
        "colab_type": "text"
      },
      "source": [
        "## Specifying the folder names/path for mini dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Qc0SKSaCVDM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Specify the folders to create a Mini Dataset of\n",
        "img_class_list = ['DownwardFacingDog','WarriorPose']\n",
        "\n",
        "# Specify where to create the Mini Dataset in\n",
        "train_path_mini = image_dir+'Split/Train_Mini'\n",
        "test_path_mini = image_dir+'Split/Test_Mini'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vBlH3SUAGJb4",
        "colab_type": "text"
      },
      "source": [
        "## Below Commented out statements are one-time run. Each time a new folder will be created \"replacing\" the old one."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mgLzFfhkCX6v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# print(\"Creating train data folder with new classes(specified in img_class_list)\")\n",
        "# create_dataset_mini(img_class_list, train_path, train_path_mini)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hqybXmm7CcD5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# print(\"Creating test data folder with new classes(specified in img_class_list)\")\n",
        "# create_dataset_mini(img_class_list, test_path, test_path_mini)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "29oKTHzDGanl",
        "colab_type": "text"
      },
      "source": [
        "## Uncomment the below two lines if the mini dataset needs to be used"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1W4lS5MECemI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Reassigning the train and test paths specified previously\n",
        "# train_path = train_path_mini\n",
        "# test_path = test_path_mini"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "heTkV9NoGfYx",
        "colab_type": "text"
      },
      "source": [
        "## List the Classes taken into consideration. The folder names were given in such a way that it'll be considered as Class names as well."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AJAFfK1afBIM",
        "colab_type": "code",
        "outputId": "2fba91a4-3cc9-4111-edb2-2549c0840e1b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        }
      },
      "source": [
        "# List of classes Used'\n",
        "classes = os.listdir(train_path)\n",
        "classes"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['LowLunge',\n",
              " 'DownwardFacingDog',\n",
              " 'TreePose',\n",
              " 'WarriorPose',\n",
              " 'Planks',\n",
              " 'ReversePlanks',\n",
              " 'SidePlanks',\n",
              " 'SeatedForwardBend',\n",
              " 'TrianglePose']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FeLPejZ7Gkm1",
        "colab_type": "text"
      },
      "source": [
        "## Get all the image files in the Train dataset folder."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aqDpggBFfIPm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_values = [] \n",
        "for c in classes:\n",
        "    train_values.append(len(os.listdir(train_path+'/'+c)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gr8eQ8I9GnvO",
        "colab_type": "text"
      },
      "source": [
        "## Display the number of images available in each of the folders in Train Set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qsv7mBztfXhw",
        "colab_type": "code",
        "outputId": "d77020ab-3e1f-460b-8bf4-c6cbcd65a211",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "train_values"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1416, 901, 4022, 1077, 187, 508, 222, 1878, 2090]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mx8D2ol4GrxH",
        "colab_type": "text"
      },
      "source": [
        "## Indices to Plot the graph"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K0blQ7qffN_7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "indexes = [0,1,2,3,4,5,6,7,8]\n",
        "#indexes = [0,1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I5B0F1ELGxOm",
        "colab_type": "text"
      },
      "source": [
        "## Distribution plot to visualize the number of images in each folder classes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lj4AfJ08fSN6",
        "colab_type": "code",
        "outputId": "31fa7a16-bcd2-44d3-891d-eeb4e7febc34",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 628
        }
      },
      "source": [
        "fig, ax = plt.subplots(1, 1, figsize=(20,10))\n",
        "plt.bar(indexes,train_values)\n",
        "plt.xticks(indexes,classes)\n",
        "plt.title(\"Distribution of Classes in Training Set\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'Distribution of Classes in Training Set')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1440x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iH5rGvOkGz0Y",
        "colab_type": "text"
      },
      "source": [
        "## Form Fields to input the model Parameters. Defualt values are set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bMRwaqWvCbqE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@title Parameters for Models\n",
        "\n",
        "#@markdown Enter the data to experiment with the model\n",
        "\n",
        "#@markdown ---\n",
        "\n",
        "image_width = 299 #@param {type:\"integer\"}\n",
        "\n",
        "image_height = 299 #@param {type:\"integer\"}\n",
        "\n",
        "epochs = 1 #@param {type:\"slider\", min:1, max:100, step:1}\n",
        "\n",
        "batchSize = 32 #@param [\"32\", \"64\", \"128\", \"256\"] {type:\"raw\"}\n",
        "\n",
        "fullConnectedLayer = 1024 #@param {type:\"integer\"}\n",
        "\n",
        "LayersToFreeze = 172 #@param {type:\"integer\"}\n",
        "\n",
        "#@markdown ---"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PpbeYh_nHnKa",
        "colab_type": "text"
      },
      "source": [
        "## Model Parameters (Same like above)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sTiMqJBjfSKU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# image_width, image_height = 299, 299 #fixed size for InceptionV3\n",
        "# epochs = 2\n",
        "# batchSize = 32\n",
        "# fullConnectedLayer = 1024\n",
        "# LayersToFreeze = 172"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TLlXETtYHrAK",
        "colab_type": "text"
      },
      "source": [
        "## Get the file count from the directory"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wn6XZPKTgsxP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_files_count(directory):\n",
        "  print('##### Getting the file Count #####')\n",
        "  # If there're no folders in the specified directly, send the count as 0\n",
        "  if not os.path.exists(directory):\n",
        "    return 0\n",
        "  count = 0\n",
        "\n",
        "  # Else, walk through the directory to get the total count\n",
        "  for val, dirs, files in os.walk(directory):\n",
        "    for dir in dirs:\n",
        "      count += len(glob(os.path.join(val, dir + \"/*\")))\n",
        "  return count"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TYUfCzKrwfAI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def setupTransferLearn(model, base_model):\n",
        "  print('##### Setting up the Transfer learning Model #####')\n",
        "  # base model is Inception model\n",
        "  # model is the additional Layers that was added\n",
        "  for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "  # Make all the layes in the Inception model as trainable False to Freeze the layers. It can not be changes further.\n",
        "  # Compile the model.\n",
        "  # Optimizer used: RMSProp,\n",
        "  # Loss Calculated: categorical_crossentropy,\n",
        "  # Accuracy metrics is measured.\n",
        "  model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r8dDpt4Gw9U0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def addAdditionalLayesToBaseModel(base_model, classes):\n",
        "  print('##### Adding layers to the base model #####')\n",
        "  ## Add additional last layers to the Base Model\n",
        "  # base model is VGG model\n",
        "  # classes: Total number of classes in consideration\n",
        "\n",
        "  x = base_model.output\n",
        "  x = GlobalAveragePooling2D()(x)\n",
        "\n",
        "  # Add a Fully Connected Layer, random init\n",
        "  x = Dense(fullConnectedLayer, activation='relu')(x)\n",
        "\n",
        "  # Add a Softmax Layer for predicting the output\n",
        "  outputLayer = Dense(classes, activation='softmax')(x)\n",
        "\n",
        "  newModel = Model(base_model.input, outputLayer)\n",
        "  return newModel"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bdGI-16uw9LH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def changeLayerPropertyForFineTune(model):\n",
        "  print('##### Freeze/UnFreeze the layers #####')\n",
        "  # model: the Model that is used for training/testing\n",
        "  ## Freeze the bottom LayersToFreeze and retrain the remaining top layers.\n",
        "  ## LayersToFreeze corresponds to the top layers in the Inception Architecture\n",
        "\n",
        "  for layer in model.layers[:LayersToFreeze]:\n",
        "     layer.trainable = False\n",
        "\n",
        "  for layer in model.layers[LayersToFreeze:]:\n",
        "     layer.trainable = True\n",
        "\n",
        "  # Compile the model.\n",
        "  # Optimizer used: Stochastic gradient descent,\n",
        "  # Learning rate and momentum\n",
        "  # Loss Calculated: categorical_crossentropy,\n",
        "  # Accuracy metrics is measured.\n",
        "  \n",
        "  model.compile(optimizer=SGD(lr=0.0001, momentum=0.9), loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lPpXP-UBw9HL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def transferLearningModel():\n",
        "  print('##### Transfer Learning model to train on Yoga Dataset #####')\n",
        "  \n",
        "  ## Get the file count in the Train path\n",
        "  totalTrainSamples = get_files_count(train_path)\n",
        "\n",
        "  ## Total Classes taken\n",
        "  totalClasses = len(glob(train_path+ \"/*\"))\n",
        "\n",
        "  ## Get the file count in the Test/Validation path\n",
        "  totalTestSamples = get_files_count(test_path)\n",
        "\n",
        "  ## Type Conversion, just in case if the enter number in the form field is not of type int.\n",
        "  epoch = int(epochs)\n",
        "\n",
        "  ## Type Conversion, just in case if the enter number in the form field is not of type int.\n",
        "  batch_size = int(batchSize)\n",
        "\n",
        "  print('##### Data Augmentation #####')\n",
        "  # Data Preparation for Train Set Using ImageDataGenerator\n",
        "\n",
        "  train_datagenerator =  ImageDataGenerator(\n",
        "      rescale = 1./255,\n",
        "      preprocessing_function=preprocess_input,\n",
        "      rotation_range = 30,\n",
        "      width_shift_range = 0.2,\n",
        "      height_shift_range = 0.2,\n",
        "      shear_range = 0.2,\n",
        "      zoom_range = 0.2,\n",
        "      horizontal_flip=True\n",
        "  )\n",
        "\n",
        "  # Data Preparation for Validation Set Using ImageDataGenerator\n",
        "  validation_datagenerator = ImageDataGenerator(\n",
        "      rescale = 1./255,\n",
        "      preprocessing_function = preprocess_input,\n",
        "      rotation_range = 30,\n",
        "      width_shift_range = 0.2,\n",
        "      height_shift_range = 0.2,\n",
        "      shear_range = 0.2,\n",
        "      zoom_range = 0.2,\n",
        "      horizontal_flip = True\n",
        "  )\n",
        "\n",
        "  ## Train set for the model\n",
        "  train_generator = train_datagenerator.flow_from_directory(\n",
        "    train_path,\n",
        "    target_size=(image_width, image_height),\n",
        "    batch_size=batch_size,\n",
        "  )\n",
        "\n",
        "  ## Validation set for the model\n",
        "  validation_generator = validation_datagenerator.flow_from_directory(\n",
        "    test_path,\n",
        "    target_size=(image_width, image_height),\n",
        "    batch_size=batch_size,\n",
        "  )\n",
        "\n",
        "  # Model Setup\n",
        "  ## InceptionV3 Model\n",
        "  ## Input Shape is 299, 299, 3\n",
        "  ## Getting the weights from pretrained model on Imagenet dataset\n",
        "  ## include_top = False To exclude the final Fully Connected Layers\n",
        "  \n",
        "  print('##### Create Model #####')\n",
        "  base_model = InceptionV3(input_shape=[image_width, image_height] + [3],weights='imagenet', include_top=False)\n",
        "  \n",
        "  ## Save the inital model setup in base_model_vgg_initial.png file\n",
        "  plot_model(base_model, to_file='base_model_inception_initial.png', show_shapes=True)\n",
        "  \n",
        "  print('##### Add Layers in Model #####')\n",
        "  ## Add bottom layers with output layer specific to the dataset under consideration\n",
        "  model = addAdditionalLayesToBaseModel(base_model, totalClasses)\n",
        "\n",
        "  ## Save the model setup after adding output layers in base_model_vgg_initial.png file\n",
        "  plot_model(model, to_file='base_model_inception_setup.png', show_shapes=True)\n",
        "  \n",
        "  ## Transfer Learning model setup\n",
        "  setupTransferLearn(model, base_model)\n",
        "\n",
        "  print('##### Model Summary #####')\n",
        "  ## Print the Model Summary\n",
        "  model.summary()\n",
        "\n",
        "  ## TensorBoard Integration\n",
        "  log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "  tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
        "  \n",
        "  ## History Object with model Accuracy and Loss values before fine tuning the model\n",
        "  history_1 = model.fit_generator(\n",
        "    train_generator,\n",
        "    epochs=epoch,\n",
        "    steps_per_epoch=totalTrainSamples,\n",
        "    validation_data=validation_generator,\n",
        "    validation_steps=totalTestSamples,\n",
        "    callbacks=[tensorboard_callback])\n",
        "  \n",
        "  print('##### Plot Train and Validation Set - Accuracy and Loss Values Before Tuning #####')\n",
        "  #plot_training(history_1)\n",
        "\n",
        "  # Fine Tune the Model by changing the Layer Trainable property\n",
        "  changeLayerPropertyForFineTune(model)\n",
        "  \n",
        "  ## History Object with model Accuracy and Loss values After fine tuning the model\n",
        "  history_2 = model.fit_generator(\n",
        "    train_generator,\n",
        "    steps_per_epoch=totalTrainSamples,\n",
        "    epochs=epoch,\n",
        "    validation_data=validation_generator,\n",
        "    validation_steps=totalTestSamples,\n",
        "    callbacks=[tensorboard_callback])\n",
        "  \n",
        "  print('##### Plot Train and Validation Set - Accuracy and Loss Values After Tuning #####')\n",
        "  #plot_training(history_2)\n",
        "\n",
        "  model.save('inception.h5')\n",
        "  ## Getting the file names from the validation set to get sample misclassified images\n",
        "  fnames = validation_generator.filenames\n",
        "\n",
        "  ## Actual classes\n",
        "  actualClass = validation_generator.classes\n",
        "  print('##### Actual Class #####', actualClass)\n",
        "\n",
        "  ## Converting the Labels to Indices\n",
        "  label2index = validation_generator.class_indices\n",
        "  idx2label = dict((v,k) for k,v in label2index.items())\n",
        "\n",
        "  ## To get the model Predictions based on Validation set\n",
        "  predictions= model.predict_generator(validation_generator, steps = validation_generator.samples/validation_generator.batch_size, verbose=0)\n",
        "\n",
        "  ## Predictions are in Float, Rounding them to get the actual classes\n",
        "  predicted_classes = np.argmax(predictions,axis=1)\n",
        "  ## print(predicted_classes)\n",
        "\n",
        "  print('##### Some Misclassified classes #####')\n",
        "  errors = np.where(predicted_classes != actualClass)[0]\n",
        "  print(\"No of errors = {}/{}\".format(len(errors),validation_generator.samples))\n",
        "\n",
        "  # for i in range(5):\n",
        "  #   pred_class = np.argmax(predictions[errors[i]])\n",
        "  #   pred_label = idx2label[pred_class]\n",
        "  #   title = 'Original label:{}, Prediction :{}, confidence : {:.3f}'.format(fnames[errors[i]].split('/')[0], pred_label, predictions[errors[i]][pred_class])\n",
        "  #   original = load_img('{}/{}'.format(test_path,fnames[errors[i]]))\n",
        "  #   plt.figure(figsize=[7,7])\n",
        "  #   plt.axis('off')\n",
        "  #   plt.title(title)\n",
        "  #   plt.imshow(original)\n",
        "  #   plt.show()\n",
        "\n",
        "  print('##### Class mapping to the Index #####')\n",
        "  print(idx2label)\n",
        "\n",
        "  print('##### Plotting Confusion Matrix #####')\n",
        "  results = confusion_matrix(actualClass, predicted_classes) \n",
        "  #print(results)\n",
        "\n",
        "  sns.set(font_scale=1.4) # for label size\n",
        "  sns.heatmap(results, annot=True)\n",
        "  plt.figure(figsize=(5,5))\n",
        "  plt.show()\n",
        "\n",
        "  print('##### Accuracy Score #####')\n",
        "  print(accuracy_score(actualClass, predicted_classes))\n",
        "\n",
        "  print('##### classification_report #####')\n",
        "  print(classification_report(actualClass, predicted_classes))\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j_YT_ihGx35H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_training(history):\n",
        "  accuracy = history.history['accuracy']\n",
        "  val_accuracy = history.history['val_accuracy']\n",
        "  loss = history.history['loss']\n",
        "  val_loss = history.history['val_loss']\n",
        "  epochs = range(len(accuracy))\n",
        "\n",
        "  plt.plot(epochs, accuracy)\n",
        "  plt.plot(epochs, val_accuracy, color='b')\n",
        "  plt.title('Training and validation accuracy')\n",
        "  plt.figure()\n",
        "\n",
        "  plt.plot(epochs, loss)\n",
        "  plt.plot(epochs, val_loss, color='b')\n",
        "  plt.title('Training and validation loss')\n",
        "  plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8zVkX9S2x30l",
        "colab_type": "code",
        "outputId": "4a4a7e92-7dff-4fd4-fdbd-a6450e5821e7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "## To create and run the model in the specified device\n",
        "with strategy.scope():\n",
        "  transferLearningModel()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "##### Transfer Learning model to train on Yoga Dataset #####\n",
            "##### Getting the file Count #####\n",
            "##### Getting the file Count #####\n",
            "##### Data Augmentation #####\n",
            "Found 12301 images belonging to 9 classes.\n",
            "Found 1686 images belonging to 9 classes.\n",
            "##### Create Model #####\n",
            "##### Add Layers in Model #####\n",
            "##### Adding layers to the base model #####\n",
            "##### Setting up the Transfer learning Model #####\n",
            "##### Model Summary #####\n",
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_2 (InputLayer)            [(None, 299, 299, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_94 (Conv2D)              (None, 149, 149, 32) 864         input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_94 (BatchNo (None, 149, 149, 32) 96          conv2d_94[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_94 (Activation)      (None, 149, 149, 32) 0           batch_normalization_94[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_95 (Conv2D)              (None, 147, 147, 32) 9216        activation_94[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_95 (BatchNo (None, 147, 147, 32) 96          conv2d_95[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_95 (Activation)      (None, 147, 147, 32) 0           batch_normalization_95[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_96 (Conv2D)              (None, 147, 147, 64) 18432       activation_95[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_96 (BatchNo (None, 147, 147, 64) 192         conv2d_96[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_96 (Activation)      (None, 147, 147, 64) 0           batch_normalization_96[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2D)  (None, 73, 73, 64)   0           activation_96[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_97 (Conv2D)              (None, 73, 73, 80)   5120        max_pooling2d_4[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_97 (BatchNo (None, 73, 73, 80)   240         conv2d_97[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_97 (Activation)      (None, 73, 73, 80)   0           batch_normalization_97[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_98 (Conv2D)              (None, 71, 71, 192)  138240      activation_97[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_98 (BatchNo (None, 71, 71, 192)  576         conv2d_98[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_98 (Activation)      (None, 71, 71, 192)  0           batch_normalization_98[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_5 (MaxPooling2D)  (None, 35, 35, 192)  0           activation_98[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_102 (Conv2D)             (None, 35, 35, 64)   12288       max_pooling2d_5[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_102 (BatchN (None, 35, 35, 64)   192         conv2d_102[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_102 (Activation)     (None, 35, 35, 64)   0           batch_normalization_102[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_100 (Conv2D)             (None, 35, 35, 48)   9216        max_pooling2d_5[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_103 (Conv2D)             (None, 35, 35, 96)   55296       activation_102[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_100 (BatchN (None, 35, 35, 48)   144         conv2d_100[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_103 (BatchN (None, 35, 35, 96)   288         conv2d_103[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_100 (Activation)     (None, 35, 35, 48)   0           batch_normalization_100[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_103 (Activation)     (None, 35, 35, 96)   0           batch_normalization_103[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_9 (AveragePoo (None, 35, 35, 192)  0           max_pooling2d_5[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_99 (Conv2D)              (None, 35, 35, 64)   12288       max_pooling2d_5[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_101 (Conv2D)             (None, 35, 35, 64)   76800       activation_100[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_104 (Conv2D)             (None, 35, 35, 96)   82944       activation_103[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_105 (Conv2D)             (None, 35, 35, 32)   6144        average_pooling2d_9[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_99 (BatchNo (None, 35, 35, 64)   192         conv2d_99[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_101 (BatchN (None, 35, 35, 64)   192         conv2d_101[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_104 (BatchN (None, 35, 35, 96)   288         conv2d_104[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_105 (BatchN (None, 35, 35, 32)   96          conv2d_105[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_99 (Activation)      (None, 35, 35, 64)   0           batch_normalization_99[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_101 (Activation)     (None, 35, 35, 64)   0           batch_normalization_101[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_104 (Activation)     (None, 35, 35, 96)   0           batch_normalization_104[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_105 (Activation)     (None, 35, 35, 32)   0           batch_normalization_105[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed0 (Concatenate)            (None, 35, 35, 256)  0           activation_99[0][0]              \n",
            "                                                                 activation_101[0][0]             \n",
            "                                                                 activation_104[0][0]             \n",
            "                                                                 activation_105[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_109 (Conv2D)             (None, 35, 35, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_109 (BatchN (None, 35, 35, 64)   192         conv2d_109[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_109 (Activation)     (None, 35, 35, 64)   0           batch_normalization_109[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_107 (Conv2D)             (None, 35, 35, 48)   12288       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_110 (Conv2D)             (None, 35, 35, 96)   55296       activation_109[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_107 (BatchN (None, 35, 35, 48)   144         conv2d_107[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_110 (BatchN (None, 35, 35, 96)   288         conv2d_110[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_107 (Activation)     (None, 35, 35, 48)   0           batch_normalization_107[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_110 (Activation)     (None, 35, 35, 96)   0           batch_normalization_110[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_10 (AveragePo (None, 35, 35, 256)  0           mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_106 (Conv2D)             (None, 35, 35, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_108 (Conv2D)             (None, 35, 35, 64)   76800       activation_107[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_111 (Conv2D)             (None, 35, 35, 96)   82944       activation_110[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_112 (Conv2D)             (None, 35, 35, 64)   16384       average_pooling2d_10[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_106 (BatchN (None, 35, 35, 64)   192         conv2d_106[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_108 (BatchN (None, 35, 35, 64)   192         conv2d_108[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_111 (BatchN (None, 35, 35, 96)   288         conv2d_111[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_112 (BatchN (None, 35, 35, 64)   192         conv2d_112[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_106 (Activation)     (None, 35, 35, 64)   0           batch_normalization_106[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_108 (Activation)     (None, 35, 35, 64)   0           batch_normalization_108[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_111 (Activation)     (None, 35, 35, 96)   0           batch_normalization_111[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_112 (Activation)     (None, 35, 35, 64)   0           batch_normalization_112[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed1 (Concatenate)            (None, 35, 35, 288)  0           activation_106[0][0]             \n",
            "                                                                 activation_108[0][0]             \n",
            "                                                                 activation_111[0][0]             \n",
            "                                                                 activation_112[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_116 (Conv2D)             (None, 35, 35, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_116 (BatchN (None, 35, 35, 64)   192         conv2d_116[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_116 (Activation)     (None, 35, 35, 64)   0           batch_normalization_116[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_114 (Conv2D)             (None, 35, 35, 48)   13824       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_117 (Conv2D)             (None, 35, 35, 96)   55296       activation_116[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_114 (BatchN (None, 35, 35, 48)   144         conv2d_114[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_117 (BatchN (None, 35, 35, 96)   288         conv2d_117[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_114 (Activation)     (None, 35, 35, 48)   0           batch_normalization_114[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_117 (Activation)     (None, 35, 35, 96)   0           batch_normalization_117[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_11 (AveragePo (None, 35, 35, 288)  0           mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_113 (Conv2D)             (None, 35, 35, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_115 (Conv2D)             (None, 35, 35, 64)   76800       activation_114[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_118 (Conv2D)             (None, 35, 35, 96)   82944       activation_117[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_119 (Conv2D)             (None, 35, 35, 64)   18432       average_pooling2d_11[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_113 (BatchN (None, 35, 35, 64)   192         conv2d_113[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_115 (BatchN (None, 35, 35, 64)   192         conv2d_115[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_118 (BatchN (None, 35, 35, 96)   288         conv2d_118[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_119 (BatchN (None, 35, 35, 64)   192         conv2d_119[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_113 (Activation)     (None, 35, 35, 64)   0           batch_normalization_113[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_115 (Activation)     (None, 35, 35, 64)   0           batch_normalization_115[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_118 (Activation)     (None, 35, 35, 96)   0           batch_normalization_118[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_119 (Activation)     (None, 35, 35, 64)   0           batch_normalization_119[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed2 (Concatenate)            (None, 35, 35, 288)  0           activation_113[0][0]             \n",
            "                                                                 activation_115[0][0]             \n",
            "                                                                 activation_118[0][0]             \n",
            "                                                                 activation_119[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_121 (Conv2D)             (None, 35, 35, 64)   18432       mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_121 (BatchN (None, 35, 35, 64)   192         conv2d_121[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_121 (Activation)     (None, 35, 35, 64)   0           batch_normalization_121[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_122 (Conv2D)             (None, 35, 35, 96)   55296       activation_121[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_122 (BatchN (None, 35, 35, 96)   288         conv2d_122[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_122 (Activation)     (None, 35, 35, 96)   0           batch_normalization_122[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_120 (Conv2D)             (None, 17, 17, 384)  995328      mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_123 (Conv2D)             (None, 17, 17, 96)   82944       activation_122[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_120 (BatchN (None, 17, 17, 384)  1152        conv2d_120[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_123 (BatchN (None, 17, 17, 96)   288         conv2d_123[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_120 (Activation)     (None, 17, 17, 384)  0           batch_normalization_120[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_123 (Activation)     (None, 17, 17, 96)   0           batch_normalization_123[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_6 (MaxPooling2D)  (None, 17, 17, 288)  0           mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed3 (Concatenate)            (None, 17, 17, 768)  0           activation_120[0][0]             \n",
            "                                                                 activation_123[0][0]             \n",
            "                                                                 max_pooling2d_6[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_128 (Conv2D)             (None, 17, 17, 128)  98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_128 (BatchN (None, 17, 17, 128)  384         conv2d_128[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_128 (Activation)     (None, 17, 17, 128)  0           batch_normalization_128[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_129 (Conv2D)             (None, 17, 17, 128)  114688      activation_128[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_129 (BatchN (None, 17, 17, 128)  384         conv2d_129[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_129 (Activation)     (None, 17, 17, 128)  0           batch_normalization_129[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_125 (Conv2D)             (None, 17, 17, 128)  98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_130 (Conv2D)             (None, 17, 17, 128)  114688      activation_129[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_125 (BatchN (None, 17, 17, 128)  384         conv2d_125[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_130 (BatchN (None, 17, 17, 128)  384         conv2d_130[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_125 (Activation)     (None, 17, 17, 128)  0           batch_normalization_125[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_130 (Activation)     (None, 17, 17, 128)  0           batch_normalization_130[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_126 (Conv2D)             (None, 17, 17, 128)  114688      activation_125[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_131 (Conv2D)             (None, 17, 17, 128)  114688      activation_130[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_126 (BatchN (None, 17, 17, 128)  384         conv2d_126[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_131 (BatchN (None, 17, 17, 128)  384         conv2d_131[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_126 (Activation)     (None, 17, 17, 128)  0           batch_normalization_126[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_131 (Activation)     (None, 17, 17, 128)  0           batch_normalization_131[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_12 (AveragePo (None, 17, 17, 768)  0           mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_124 (Conv2D)             (None, 17, 17, 192)  147456      mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_127 (Conv2D)             (None, 17, 17, 192)  172032      activation_126[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_132 (Conv2D)             (None, 17, 17, 192)  172032      activation_131[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_133 (Conv2D)             (None, 17, 17, 192)  147456      average_pooling2d_12[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_124 (BatchN (None, 17, 17, 192)  576         conv2d_124[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_127 (BatchN (None, 17, 17, 192)  576         conv2d_127[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_132 (BatchN (None, 17, 17, 192)  576         conv2d_132[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_133 (BatchN (None, 17, 17, 192)  576         conv2d_133[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_124 (Activation)     (None, 17, 17, 192)  0           batch_normalization_124[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_127 (Activation)     (None, 17, 17, 192)  0           batch_normalization_127[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_132 (Activation)     (None, 17, 17, 192)  0           batch_normalization_132[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_133 (Activation)     (None, 17, 17, 192)  0           batch_normalization_133[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed4 (Concatenate)            (None, 17, 17, 768)  0           activation_124[0][0]             \n",
            "                                                                 activation_127[0][0]             \n",
            "                                                                 activation_132[0][0]             \n",
            "                                                                 activation_133[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_138 (Conv2D)             (None, 17, 17, 160)  122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_138 (BatchN (None, 17, 17, 160)  480         conv2d_138[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_138 (Activation)     (None, 17, 17, 160)  0           batch_normalization_138[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_139 (Conv2D)             (None, 17, 17, 160)  179200      activation_138[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_139 (BatchN (None, 17, 17, 160)  480         conv2d_139[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_139 (Activation)     (None, 17, 17, 160)  0           batch_normalization_139[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_135 (Conv2D)             (None, 17, 17, 160)  122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_140 (Conv2D)             (None, 17, 17, 160)  179200      activation_139[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_135 (BatchN (None, 17, 17, 160)  480         conv2d_135[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_140 (BatchN (None, 17, 17, 160)  480         conv2d_140[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_135 (Activation)     (None, 17, 17, 160)  0           batch_normalization_135[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_140 (Activation)     (None, 17, 17, 160)  0           batch_normalization_140[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_136 (Conv2D)             (None, 17, 17, 160)  179200      activation_135[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_141 (Conv2D)             (None, 17, 17, 160)  179200      activation_140[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_136 (BatchN (None, 17, 17, 160)  480         conv2d_136[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_141 (BatchN (None, 17, 17, 160)  480         conv2d_141[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_136 (Activation)     (None, 17, 17, 160)  0           batch_normalization_136[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_141 (Activation)     (None, 17, 17, 160)  0           batch_normalization_141[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_13 (AveragePo (None, 17, 17, 768)  0           mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_134 (Conv2D)             (None, 17, 17, 192)  147456      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_137 (Conv2D)             (None, 17, 17, 192)  215040      activation_136[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_142 (Conv2D)             (None, 17, 17, 192)  215040      activation_141[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_143 (Conv2D)             (None, 17, 17, 192)  147456      average_pooling2d_13[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_134 (BatchN (None, 17, 17, 192)  576         conv2d_134[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_137 (BatchN (None, 17, 17, 192)  576         conv2d_137[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_142 (BatchN (None, 17, 17, 192)  576         conv2d_142[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_143 (BatchN (None, 17, 17, 192)  576         conv2d_143[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_134 (Activation)     (None, 17, 17, 192)  0           batch_normalization_134[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_137 (Activation)     (None, 17, 17, 192)  0           batch_normalization_137[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_142 (Activation)     (None, 17, 17, 192)  0           batch_normalization_142[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_143 (Activation)     (None, 17, 17, 192)  0           batch_normalization_143[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed5 (Concatenate)            (None, 17, 17, 768)  0           activation_134[0][0]             \n",
            "                                                                 activation_137[0][0]             \n",
            "                                                                 activation_142[0][0]             \n",
            "                                                                 activation_143[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_148 (Conv2D)             (None, 17, 17, 160)  122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_148 (BatchN (None, 17, 17, 160)  480         conv2d_148[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_148 (Activation)     (None, 17, 17, 160)  0           batch_normalization_148[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_149 (Conv2D)             (None, 17, 17, 160)  179200      activation_148[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_149 (BatchN (None, 17, 17, 160)  480         conv2d_149[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_149 (Activation)     (None, 17, 17, 160)  0           batch_normalization_149[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_145 (Conv2D)             (None, 17, 17, 160)  122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_150 (Conv2D)             (None, 17, 17, 160)  179200      activation_149[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_145 (BatchN (None, 17, 17, 160)  480         conv2d_145[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_150 (BatchN (None, 17, 17, 160)  480         conv2d_150[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_145 (Activation)     (None, 17, 17, 160)  0           batch_normalization_145[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_150 (Activation)     (None, 17, 17, 160)  0           batch_normalization_150[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_146 (Conv2D)             (None, 17, 17, 160)  179200      activation_145[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_151 (Conv2D)             (None, 17, 17, 160)  179200      activation_150[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_146 (BatchN (None, 17, 17, 160)  480         conv2d_146[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_151 (BatchN (None, 17, 17, 160)  480         conv2d_151[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_146 (Activation)     (None, 17, 17, 160)  0           batch_normalization_146[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_151 (Activation)     (None, 17, 17, 160)  0           batch_normalization_151[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_14 (AveragePo (None, 17, 17, 768)  0           mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_144 (Conv2D)             (None, 17, 17, 192)  147456      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_147 (Conv2D)             (None, 17, 17, 192)  215040      activation_146[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_152 (Conv2D)             (None, 17, 17, 192)  215040      activation_151[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_153 (Conv2D)             (None, 17, 17, 192)  147456      average_pooling2d_14[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_144 (BatchN (None, 17, 17, 192)  576         conv2d_144[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_147 (BatchN (None, 17, 17, 192)  576         conv2d_147[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_152 (BatchN (None, 17, 17, 192)  576         conv2d_152[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_153 (BatchN (None, 17, 17, 192)  576         conv2d_153[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_144 (Activation)     (None, 17, 17, 192)  0           batch_normalization_144[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_147 (Activation)     (None, 17, 17, 192)  0           batch_normalization_147[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_152 (Activation)     (None, 17, 17, 192)  0           batch_normalization_152[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_153 (Activation)     (None, 17, 17, 192)  0           batch_normalization_153[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed6 (Concatenate)            (None, 17, 17, 768)  0           activation_144[0][0]             \n",
            "                                                                 activation_147[0][0]             \n",
            "                                                                 activation_152[0][0]             \n",
            "                                                                 activation_153[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_158 (Conv2D)             (None, 17, 17, 192)  147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_158 (BatchN (None, 17, 17, 192)  576         conv2d_158[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_158 (Activation)     (None, 17, 17, 192)  0           batch_normalization_158[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_159 (Conv2D)             (None, 17, 17, 192)  258048      activation_158[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_159 (BatchN (None, 17, 17, 192)  576         conv2d_159[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_159 (Activation)     (None, 17, 17, 192)  0           batch_normalization_159[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_155 (Conv2D)             (None, 17, 17, 192)  147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_160 (Conv2D)             (None, 17, 17, 192)  258048      activation_159[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_155 (BatchN (None, 17, 17, 192)  576         conv2d_155[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_160 (BatchN (None, 17, 17, 192)  576         conv2d_160[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_155 (Activation)     (None, 17, 17, 192)  0           batch_normalization_155[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_160 (Activation)     (None, 17, 17, 192)  0           batch_normalization_160[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_156 (Conv2D)             (None, 17, 17, 192)  258048      activation_155[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_161 (Conv2D)             (None, 17, 17, 192)  258048      activation_160[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_156 (BatchN (None, 17, 17, 192)  576         conv2d_156[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_161 (BatchN (None, 17, 17, 192)  576         conv2d_161[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_156 (Activation)     (None, 17, 17, 192)  0           batch_normalization_156[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_161 (Activation)     (None, 17, 17, 192)  0           batch_normalization_161[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_15 (AveragePo (None, 17, 17, 768)  0           mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_154 (Conv2D)             (None, 17, 17, 192)  147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_157 (Conv2D)             (None, 17, 17, 192)  258048      activation_156[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_162 (Conv2D)             (None, 17, 17, 192)  258048      activation_161[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_163 (Conv2D)             (None, 17, 17, 192)  147456      average_pooling2d_15[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_154 (BatchN (None, 17, 17, 192)  576         conv2d_154[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_157 (BatchN (None, 17, 17, 192)  576         conv2d_157[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_162 (BatchN (None, 17, 17, 192)  576         conv2d_162[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_163 (BatchN (None, 17, 17, 192)  576         conv2d_163[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_154 (Activation)     (None, 17, 17, 192)  0           batch_normalization_154[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_157 (Activation)     (None, 17, 17, 192)  0           batch_normalization_157[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_162 (Activation)     (None, 17, 17, 192)  0           batch_normalization_162[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_163 (Activation)     (None, 17, 17, 192)  0           batch_normalization_163[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed7 (Concatenate)            (None, 17, 17, 768)  0           activation_154[0][0]             \n",
            "                                                                 activation_157[0][0]             \n",
            "                                                                 activation_162[0][0]             \n",
            "                                                                 activation_163[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_166 (Conv2D)             (None, 17, 17, 192)  147456      mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_166 (BatchN (None, 17, 17, 192)  576         conv2d_166[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_166 (Activation)     (None, 17, 17, 192)  0           batch_normalization_166[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_167 (Conv2D)             (None, 17, 17, 192)  258048      activation_166[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_167 (BatchN (None, 17, 17, 192)  576         conv2d_167[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_167 (Activation)     (None, 17, 17, 192)  0           batch_normalization_167[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_164 (Conv2D)             (None, 17, 17, 192)  147456      mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_168 (Conv2D)             (None, 17, 17, 192)  258048      activation_167[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_164 (BatchN (None, 17, 17, 192)  576         conv2d_164[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_168 (BatchN (None, 17, 17, 192)  576         conv2d_168[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_164 (Activation)     (None, 17, 17, 192)  0           batch_normalization_164[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_168 (Activation)     (None, 17, 17, 192)  0           batch_normalization_168[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_165 (Conv2D)             (None, 8, 8, 320)    552960      activation_164[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_169 (Conv2D)             (None, 8, 8, 192)    331776      activation_168[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_165 (BatchN (None, 8, 8, 320)    960         conv2d_165[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_169 (BatchN (None, 8, 8, 192)    576         conv2d_169[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_165 (Activation)     (None, 8, 8, 320)    0           batch_normalization_165[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_169 (Activation)     (None, 8, 8, 192)    0           batch_normalization_169[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_7 (MaxPooling2D)  (None, 8, 8, 768)    0           mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed8 (Concatenate)            (None, 8, 8, 1280)   0           activation_165[0][0]             \n",
            "                                                                 activation_169[0][0]             \n",
            "                                                                 max_pooling2d_7[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_174 (Conv2D)             (None, 8, 8, 448)    573440      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_174 (BatchN (None, 8, 8, 448)    1344        conv2d_174[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_174 (Activation)     (None, 8, 8, 448)    0           batch_normalization_174[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_171 (Conv2D)             (None, 8, 8, 384)    491520      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_175 (Conv2D)             (None, 8, 8, 384)    1548288     activation_174[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_171 (BatchN (None, 8, 8, 384)    1152        conv2d_171[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_175 (BatchN (None, 8, 8, 384)    1152        conv2d_175[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_171 (Activation)     (None, 8, 8, 384)    0           batch_normalization_171[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_175 (Activation)     (None, 8, 8, 384)    0           batch_normalization_175[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_172 (Conv2D)             (None, 8, 8, 384)    442368      activation_171[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_173 (Conv2D)             (None, 8, 8, 384)    442368      activation_171[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_176 (Conv2D)             (None, 8, 8, 384)    442368      activation_175[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_177 (Conv2D)             (None, 8, 8, 384)    442368      activation_175[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_16 (AveragePo (None, 8, 8, 1280)   0           mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_170 (Conv2D)             (None, 8, 8, 320)    409600      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_172 (BatchN (None, 8, 8, 384)    1152        conv2d_172[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_173 (BatchN (None, 8, 8, 384)    1152        conv2d_173[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_176 (BatchN (None, 8, 8, 384)    1152        conv2d_176[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_177 (BatchN (None, 8, 8, 384)    1152        conv2d_177[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_178 (Conv2D)             (None, 8, 8, 192)    245760      average_pooling2d_16[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_170 (BatchN (None, 8, 8, 320)    960         conv2d_170[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_172 (Activation)     (None, 8, 8, 384)    0           batch_normalization_172[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_173 (Activation)     (None, 8, 8, 384)    0           batch_normalization_173[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_176 (Activation)     (None, 8, 8, 384)    0           batch_normalization_176[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_177 (Activation)     (None, 8, 8, 384)    0           batch_normalization_177[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_178 (BatchN (None, 8, 8, 192)    576         conv2d_178[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_170 (Activation)     (None, 8, 8, 320)    0           batch_normalization_170[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed9_0 (Concatenate)          (None, 8, 8, 768)    0           activation_172[0][0]             \n",
            "                                                                 activation_173[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_2 (Concatenate)     (None, 8, 8, 768)    0           activation_176[0][0]             \n",
            "                                                                 activation_177[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_178 (Activation)     (None, 8, 8, 192)    0           batch_normalization_178[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed9 (Concatenate)            (None, 8, 8, 2048)   0           activation_170[0][0]             \n",
            "                                                                 mixed9_0[0][0]                   \n",
            "                                                                 concatenate_2[0][0]              \n",
            "                                                                 activation_178[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_183 (Conv2D)             (None, 8, 8, 448)    917504      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_183 (BatchN (None, 8, 8, 448)    1344        conv2d_183[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_183 (Activation)     (None, 8, 8, 448)    0           batch_normalization_183[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_180 (Conv2D)             (None, 8, 8, 384)    786432      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_184 (Conv2D)             (None, 8, 8, 384)    1548288     activation_183[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_180 (BatchN (None, 8, 8, 384)    1152        conv2d_180[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_184 (BatchN (None, 8, 8, 384)    1152        conv2d_184[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_180 (Activation)     (None, 8, 8, 384)    0           batch_normalization_180[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_184 (Activation)     (None, 8, 8, 384)    0           batch_normalization_184[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_181 (Conv2D)             (None, 8, 8, 384)    442368      activation_180[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_182 (Conv2D)             (None, 8, 8, 384)    442368      activation_180[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_185 (Conv2D)             (None, 8, 8, 384)    442368      activation_184[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_186 (Conv2D)             (None, 8, 8, 384)    442368      activation_184[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_17 (AveragePo (None, 8, 8, 2048)   0           mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_179 (Conv2D)             (None, 8, 8, 320)    655360      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_181 (BatchN (None, 8, 8, 384)    1152        conv2d_181[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_182 (BatchN (None, 8, 8, 384)    1152        conv2d_182[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_185 (BatchN (None, 8, 8, 384)    1152        conv2d_185[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_186 (BatchN (None, 8, 8, 384)    1152        conv2d_186[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_187 (Conv2D)             (None, 8, 8, 192)    393216      average_pooling2d_17[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_179 (BatchN (None, 8, 8, 320)    960         conv2d_179[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_181 (Activation)     (None, 8, 8, 384)    0           batch_normalization_181[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_182 (Activation)     (None, 8, 8, 384)    0           batch_normalization_182[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_185 (Activation)     (None, 8, 8, 384)    0           batch_normalization_185[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_186 (Activation)     (None, 8, 8, 384)    0           batch_normalization_186[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_187 (BatchN (None, 8, 8, 192)    576         conv2d_187[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_179 (Activation)     (None, 8, 8, 320)    0           batch_normalization_179[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed9_1 (Concatenate)          (None, 8, 8, 768)    0           activation_181[0][0]             \n",
            "                                                                 activation_182[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_3 (Concatenate)     (None, 8, 8, 768)    0           activation_185[0][0]             \n",
            "                                                                 activation_186[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_187 (Activation)     (None, 8, 8, 192)    0           batch_normalization_187[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed10 (Concatenate)           (None, 8, 8, 2048)   0           activation_179[0][0]             \n",
            "                                                                 mixed9_1[0][0]                   \n",
            "                                                                 concatenate_3[0][0]              \n",
            "                                                                 activation_187[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling2d_1 (Glo (None, 2048)         0           mixed10[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 1024)         2098176     global_average_pooling2d_1[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 9)            9225        dense_2[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 23,910,185\n",
            "Trainable params: 2,107,401\n",
            "Non-trainable params: 21,802,784\n",
            "__________________________________________________________________________________________________\n",
            "12301/12301 [==============================] - 15405s 1s/step - loss: 1.5231 - accuracy: 0.4813 - val_loss: 1.4247 - val_accuracy: 0.5240\n",
            "##### Plot Train and Validation Set - Accuracy and Loss Values Before Tuning #####\n",
            "##### Freeze/UnFreeze the layers #####\n",
            "12200/12301 [============================>.] - ETA: 1:43 - loss: 1.3905 - accuracy: 0.5582"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}