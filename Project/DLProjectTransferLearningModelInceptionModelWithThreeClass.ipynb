{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DLProjectTransferLearningModelInceptionModelWithThreeClass.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/akshaya-nagarajan/DeepLearningProjects/blob/master/Project/DLProjectTransferLearningModelInceptionModelWithThreeClass.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sKB2bZU0FEyj",
        "colab_type": "text"
      },
      "source": [
        "## Mounting the Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vL6HRkt5w3sq",
        "colab_type": "code",
        "outputId": "a43ff6f3-c726-4771-eef5-c605cdcb9dc4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive/', force_remount=True)\n",
        "root_dir = \"/content/gdrive/My Drive/Deep Learning project/\"\n",
        "image_dir = root_dir + 'Images/'"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bf5-lQg-FHWW",
        "colab_type": "text"
      },
      "source": [
        "## To determine which version of TensorFlow being used"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qt4QFYdGZP4g",
        "colab_type": "code",
        "outputId": "e8a39958-455a-4f26-964e-5f0cf4da43e2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        }
      },
      "source": [
        "# To determine which version you're using:\n",
        "!pip show tensorflow"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Name: tensorflow\n",
            "Version: 2.2.0\n",
            "Summary: TensorFlow is an open source machine learning framework for everyone.\n",
            "Home-page: https://www.tensorflow.org/\n",
            "Author: Google Inc.\n",
            "Author-email: packages@tensorflow.org\n",
            "License: Apache 2.0\n",
            "Location: /usr/local/lib/python3.6/dist-packages\n",
            "Requires: google-pasta, astunparse, termcolor, grpcio, absl-py, tensorflow-estimator, protobuf, numpy, wheel, scipy, h5py, tensorboard, keras-preprocessing, six, opt-einsum, wrapt, gast\n",
            "Required-by: fancyimpute\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dkDtP-VnFLH2",
        "colab_type": "text"
      },
      "source": [
        "## Install required Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "prqeDU_-QkWs",
        "colab_type": "code",
        "outputId": "ea479aad-33dd-4cad-a1dd-8fe00e9a4258",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "import tensorflow\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img, save_img\n",
        "from tensorflow.keras.layers import Input, Lambda, Dense, Flatten, GlobalAveragePooling2D\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.applications.vgg16 import VGG16\n",
        "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.utils import plot_model\n",
        "from tensorflow.keras.applications.inception_v3 import InceptionV3, preprocess_input\n",
        "\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "from tensorflow.keras.callbacks import TensorBoard\n",
        "import time\n",
        "import datetime\n",
        "\n",
        "# Load the TensorBoard notebook extension\n",
        "%load_ext tensorboard \n",
        "\n",
        "from glob import glob\n",
        "import numpy as np\n",
        "from numpy import expand_dims\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
        "\n",
        "import seaborn as sns\n",
        "sns.set(style=\"white\")\n",
        "sns.set(style=\"whitegrid\", color_codes=True)\n",
        "\n",
        "import os\n",
        "from shutil import copy\n",
        "from shutil import copytree, rmtree\n",
        "import argparse\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "plt.style.use(\"ggplot\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pvq1fiDBn5O7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import tensorflow.compat.v1 as tf\n",
        "# #To make tf 2.0 compatible with tf1.0 code, we disable the tf2.0 functionalities\n",
        "# tf.disable_eager_execution()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5qgMDKm3FSL9",
        "colab_type": "text"
      },
      "source": [
        "## Detect hardware and return appropriate distribution strategies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WNIrL4CoFUxs",
        "colab_type": "code",
        "outputId": "dcaa89e3-5a46-4149-9f90-17513bb74ac4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "try:\n",
        "    # TPU detection. No parameters necessary if TPU_NAME environment variable is set. On Kaggle this is always the case.\n",
        "    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
        "    print('Running on TPU ', tpu.master())\n",
        "except ValueError:\n",
        "    tpu = None\n",
        "\n",
        "if tpu:\n",
        "    tf.config.experimental_connect_to_cluster(tpu)\n",
        "    tf.tpu.experimental.initialize_tpu_system(tpu)\n",
        "    strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
        "else:\n",
        "    # default distribution strategy in Tensorflow. Works on CPU and single GPU.\n",
        "    strategy = tf.distribute.get_strategy()\n",
        "\n",
        "print(\"REPLICAS: \", strategy.num_replicas_in_sync)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "REPLICAS:  1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MDgF8e3WFZlV",
        "colab_type": "text"
      },
      "source": [
        "## This is the TPU initialization code that has to be at the beginning.(Commented)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HgT-7uCkjbe4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu='grpc://' + os.environ['COLAB_TPU_ADDR'])\n",
        "# tf.config.experimental_connect_to_cluster(resolver)\n",
        "# # This is the TPU initialization code that has to be at the beginning.\n",
        "# tf.tpu.experimental.initialize_tpu_system(resolver)\n",
        "# strategy = tf.distribute.experimental.TPUStrategy(resolver)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZCKoAj7rFb1R",
        "colab_type": "text"
      },
      "source": [
        "## Displaying the Train Folder in the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bdIYsPp-dhaO",
        "colab_type": "code",
        "outputId": "95a39e37-92ed-438c-d61e-1b1a66b20dc1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        }
      },
      "source": [
        "train_folders = glob(image_dir+'Split/Train/*')\n",
        "# Lists all the folders in train set\n",
        "train_folders"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/content/gdrive/My Drive/Deep Learning project/Images/Split/Train/LowLunge',\n",
              " '/content/gdrive/My Drive/Deep Learning project/Images/Split/Train/DownwardFacingDog',\n",
              " '/content/gdrive/My Drive/Deep Learning project/Images/Split/Train/TreePose',\n",
              " '/content/gdrive/My Drive/Deep Learning project/Images/Split/Train/WarriorPose',\n",
              " '/content/gdrive/My Drive/Deep Learning project/Images/Split/Train/Planks',\n",
              " '/content/gdrive/My Drive/Deep Learning project/Images/Split/Train/ReversePlanks',\n",
              " '/content/gdrive/My Drive/Deep Learning project/Images/Split/Train/SidePlanks',\n",
              " '/content/gdrive/My Drive/Deep Learning project/Images/Split/Train/SeatedForwardBend',\n",
              " '/content/gdrive/My Drive/Deep Learning project/Images/Split/Train/TrianglePose']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EiuqqB2fFhaF",
        "colab_type": "text"
      },
      "source": [
        "## Displaying the Test Folder in the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gkf84zU1d3Iw",
        "colab_type": "code",
        "outputId": "b19ff18a-e4cb-49b0-c740-ad861798d86e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        }
      },
      "source": [
        "test_folders = glob(image_dir+'Split/Test/*')\n",
        "# Lists all the folders in test set\n",
        "test_folders"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/content/gdrive/My Drive/Deep Learning project/Images/Split/Test/LowLunge',\n",
              " '/content/gdrive/My Drive/Deep Learning project/Images/Split/Test/DownwardFacingDog',\n",
              " '/content/gdrive/My Drive/Deep Learning project/Images/Split/Test/TreePose',\n",
              " '/content/gdrive/My Drive/Deep Learning project/Images/Split/Test/WarriorPose',\n",
              " '/content/gdrive/My Drive/Deep Learning project/Images/Split/Test/Planks',\n",
              " '/content/gdrive/My Drive/Deep Learning project/Images/Split/Test/ReversePlanks',\n",
              " '/content/gdrive/My Drive/Deep Learning project/Images/Split/Test/SidePlanks',\n",
              " '/content/gdrive/My Drive/Deep Learning project/Images/Split/Test/SeatedForwardBend',\n",
              " '/content/gdrive/My Drive/Deep Learning project/Images/Split/Test/TrianglePose']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "niIZ0CVzFrEG",
        "colab_type": "text"
      },
      "source": [
        "## Specifying the Train-Test paths "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k5jHoTGZd_e1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Actual train and test paths\n",
        "train_path = image_dir+'Split/Train'\n",
        "test_path = image_dir+'Split/Test'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7kLlvjZ4FyaP",
        "colab_type": "text"
      },
      "source": [
        "## Creating a Mini Dataset for Testing Purposes and for other Multiple runs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HaUnlfhXCSPF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_dataset_mini(img_list, source, destination):\n",
        "  if os.path.exists(destination):\n",
        "    # removing Mini dataset folder (if it already exists) folders, so that we will have only the classes that we want\n",
        "    rmtree(destination) \n",
        "  # Make the destination directories\n",
        "  os.makedirs(destination)\n",
        "  # Iterate through each image specified in the image list and get all the images from that folder only\n",
        "  \n",
        "  for img_item in img_list :\n",
        "    print(\"Copying images into\",img_item)\n",
        "    # Copy the images from source to destination\n",
        "    copytree(os.path.join(source, img_item), os.path.join(destination, img_item))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q4ws3uPpF5Gn",
        "colab_type": "text"
      },
      "source": [
        "## Specifying the folder names/path for mini dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Qc0SKSaCVDM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Specify the folders to create a Mini Dataset of\n",
        "img_class_list = ['Planks','SidePlanks','ReversePlanks']\n",
        "\n",
        "# Specify where to create the Mini Dataset in\n",
        "train_path_mini = image_dir+'Split/Train_Mini'\n",
        "test_path_mini = image_dir+'Split/Test_Mini'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vBlH3SUAGJb4",
        "colab_type": "text"
      },
      "source": [
        "## Below Commented out statements are one-time run. Each time a new folder will be created \"replacing\" the old one."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mgLzFfhkCX6v",
        "colab_type": "code",
        "outputId": "668943c9-f4c3-4e54-915a-cd70f4ab9255",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        }
      },
      "source": [
        "print(\"Creating train data folder with new classes(specified in img_class_list)\")\n",
        "create_dataset_mini(img_class_list, train_path, train_path_mini)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Creating train data folder with new classes(specified in img_class_list)\n",
            "Copying images into Planks\n",
            "Copying images into SidePlanks\n",
            "Copying images into ReversePlanks\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hqybXmm7CcD5",
        "colab_type": "code",
        "outputId": "1c5763c0-2479-44f6-a90e-a4b224c4cb8d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        }
      },
      "source": [
        "print(\"Creating test data folder with new classes(specified in img_class_list)\")\n",
        "create_dataset_mini(img_class_list, test_path, test_path_mini)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Creating test data folder with new classes(specified in img_class_list)\n",
            "Copying images into Planks\n",
            "Copying images into SidePlanks\n",
            "Copying images into ReversePlanks\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "29oKTHzDGanl",
        "colab_type": "text"
      },
      "source": [
        "## Uncomment the below two lines if the mini dataset needs to be used"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1W4lS5MECemI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Reassigning the train and test paths specified previously\n",
        "train_path = train_path_mini\n",
        "test_path = test_path_mini"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "heTkV9NoGfYx",
        "colab_type": "text"
      },
      "source": [
        "## List the Classes taken into consideration. The folder names were given in such a way that it'll be considered as Class names as well."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AJAFfK1afBIM",
        "colab_type": "code",
        "outputId": "e49e2029-e3f2-432a-fff6-e32eb54564b0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# List of classes Used'\n",
        "classes = os.listdir(train_path)\n",
        "classes"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Planks', 'SidePlanks', 'ReversePlanks']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FeLPejZ7Gkm1",
        "colab_type": "text"
      },
      "source": [
        "## Get all the image files in the Train dataset folder."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aqDpggBFfIPm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_values = [] \n",
        "for c in classes:\n",
        "    train_values.append(len(os.listdir(train_path+'/'+c)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gr8eQ8I9GnvO",
        "colab_type": "text"
      },
      "source": [
        "## Display the number of images available in each of the folders in Train Set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qsv7mBztfXhw",
        "colab_type": "code",
        "outputId": "7dcc08f7-1c0b-45b2-f9d7-56c59b83c260",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "train_values"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[187, 222, 508]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mx8D2ol4GrxH",
        "colab_type": "text"
      },
      "source": [
        "## Indices to Plot the graph"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K0blQ7qffN_7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#indexes = [0,1,2,3,4,5,6,7,8]\n",
        "indexes = [0,1,2]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I5B0F1ELGxOm",
        "colab_type": "text"
      },
      "source": [
        "## Distribution plot to visualize the number of images in each folder classes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lj4AfJ08fSN6",
        "colab_type": "code",
        "outputId": "c6b512e1-d055-4726-f00c-8225795d6325",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 628
        }
      },
      "source": [
        "fig, ax = plt.subplots(1, 1, figsize=(20,10))\n",
        "plt.bar(indexes,train_values)\n",
        "plt.xticks(indexes,classes)\n",
        "plt.title(\"Distribution of Classes in Training Set\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'Distribution of Classes in Training Set')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1440x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iH5rGvOkGz0Y",
        "colab_type": "text"
      },
      "source": [
        "## Form Fields to input the model Parameters. Defualt values are set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bMRwaqWvCbqE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@title Parameters for Models\n",
        "\n",
        "#@markdown Enter the data to experiment with the model\n",
        "\n",
        "#@markdown ---\n",
        "\n",
        "image_width = 299 #@param {type:\"integer\"}\n",
        "\n",
        "image_height = 299 #@param {type:\"integer\"}\n",
        "\n",
        "epochs = 1 #@param {type:\"slider\", min:1, max:100, step:1}\n",
        "\n",
        "batchSize = 32 #@param [\"32\", \"64\", \"128\", \"256\"] {type:\"raw\"}\n",
        "\n",
        "fullConnectedLayer = 1024 #@param {type:\"integer\"}\n",
        "\n",
        "LayersToFreeze = 172 #@param {type:\"integer\"}\n",
        "\n",
        "#@markdown ---"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PpbeYh_nHnKa",
        "colab_type": "text"
      },
      "source": [
        "## Model Parameters (Same like above)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sTiMqJBjfSKU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# image_width, image_height = 299, 299 #fixed size for InceptionV3\n",
        "# epochs = 2\n",
        "# batchSize = 32\n",
        "# fullConnectedLayer = 1024\n",
        "# LayersToFreeze = 172"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TLlXETtYHrAK",
        "colab_type": "text"
      },
      "source": [
        "## Get the file count from the directory"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wn6XZPKTgsxP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_files_count(directory):\n",
        "  print('##### Getting the file Count #####')\n",
        "  # If there're no folders in the specified directly, send the count as 0\n",
        "  if not os.path.exists(directory):\n",
        "    return 0\n",
        "  count = 0\n",
        "\n",
        "  # Else, walk through the directory to get the total count\n",
        "  for val, dirs, files in os.walk(directory):\n",
        "    for dir in dirs:\n",
        "      count += len(glob(os.path.join(val, dir + \"/*\")))\n",
        "  return count"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TYUfCzKrwfAI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def setupTransferLearn(model, base_model):\n",
        "  print('##### Setting up the Transfer learning Model #####')\n",
        "  # base model is Inception model\n",
        "  # model is the additional Layers that was added\n",
        "  for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "  # Make all the layes in the Inception model as trainable False to Freeze the layers. It can not be changes further.\n",
        "  # Compile the model.\n",
        "  # Optimizer used: RMSProp,\n",
        "  # Loss Calculated: categorical_crossentropy,\n",
        "  # Accuracy metrics is measured.\n",
        "  model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r8dDpt4Gw9U0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def addAdditionalLayesToBaseModel(base_model, classes):\n",
        "  print('##### Adding layers to the base model #####')\n",
        "  ## Add additional last layers to the Base Model\n",
        "  # base model is VGG model\n",
        "  # classes: Total number of classes in consideration\n",
        "\n",
        "  x = base_model.output\n",
        "  x = GlobalAveragePooling2D()(x)\n",
        "\n",
        "  # Add a Fully Connected Layer, random init\n",
        "  x = Dense(fullConnectedLayer, activation='relu')(x)\n",
        "\n",
        "  # Add a Softmax Layer for predicting the output\n",
        "  outputLayer = Dense(classes, activation='softmax')(x)\n",
        "\n",
        "  newModel = Model(base_model.input, outputLayer)\n",
        "  return newModel"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bdGI-16uw9LH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def changeLayerPropertyForFineTune(model):\n",
        "  print('##### Freeze/UnFreeze the layers #####')\n",
        "  # model: the Model that is used for training/testing\n",
        "  ## Freeze the bottom LayersToFreeze and retrain the remaining top layers.\n",
        "  ## LayersToFreeze corresponds to the top layers in the Inception Architecture\n",
        "\n",
        "  for layer in model.layers[:LayersToFreeze]:\n",
        "     layer.trainable = False\n",
        "\n",
        "  for layer in model.layers[LayersToFreeze:]:\n",
        "     layer.trainable = True\n",
        "\n",
        "  # Compile the model.\n",
        "  # Optimizer used: Stochastic gradient descent,\n",
        "  # Learning rate and momentum\n",
        "  # Loss Calculated: categorical_crossentropy,\n",
        "  # Accuracy metrics is measured.\n",
        "  \n",
        "  model.compile(optimizer=SGD(lr=0.0001, momentum=0.9), loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lPpXP-UBw9HL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def transferLearningModel():\n",
        "  print('##### Transfer Learning model to train on Yoga Dataset #####')\n",
        "  \n",
        "  ## Get the file count in the Train path\n",
        "  totalTrainSamples = get_files_count(train_path)\n",
        "\n",
        "  ## Total Classes taken\n",
        "  totalClasses = len(glob(train_path+ \"/*\"))\n",
        "\n",
        "  ## Get the file count in the Test/Validation path\n",
        "  totalTestSamples = get_files_count(test_path)\n",
        "\n",
        "  ## Type Conversion, just in case if the enter number in the form field is not of type int.\n",
        "  epoch = int(epochs)\n",
        "\n",
        "  ## Type Conversion, just in case if the enter number in the form field is not of type int.\n",
        "  batch_size = int(batchSize)\n",
        "\n",
        "  print('##### Data Augmentation #####')\n",
        "  # Data Preparation for Train Set Using ImageDataGenerator\n",
        "\n",
        "  train_datagenerator =  ImageDataGenerator(\n",
        "      rescale = 1./255,\n",
        "      preprocessing_function=preprocess_input,\n",
        "      rotation_range = 30,\n",
        "      width_shift_range = 0.2,\n",
        "      height_shift_range = 0.2,\n",
        "      shear_range = 0.2,\n",
        "      zoom_range = 0.2,\n",
        "      horizontal_flip=True\n",
        "  )\n",
        "\n",
        "  # Data Preparation for Validation Set Using ImageDataGenerator\n",
        "  validation_datagenerator = ImageDataGenerator(\n",
        "      rescale = 1./255,\n",
        "      preprocessing_function = preprocess_input,\n",
        "      rotation_range = 30,\n",
        "      width_shift_range = 0.2,\n",
        "      height_shift_range = 0.2,\n",
        "      shear_range = 0.2,\n",
        "      zoom_range = 0.2,\n",
        "      horizontal_flip = True\n",
        "  )\n",
        "\n",
        "  ## Train set for the model\n",
        "  train_generator = train_datagenerator.flow_from_directory(\n",
        "    train_path,\n",
        "    target_size=(image_width, image_height),\n",
        "    batch_size=batch_size,\n",
        "  )\n",
        "\n",
        "  ## Validation set for the model\n",
        "  validation_generator = validation_datagenerator.flow_from_directory(\n",
        "    test_path,\n",
        "    target_size=(image_width, image_height),\n",
        "    batch_size=batch_size,\n",
        "  )\n",
        "\n",
        "  # Model Setup\n",
        "  ## InceptionV3 Model\n",
        "  ## Input Shape is 299, 299, 3\n",
        "  ## Getting the weights from pretrained model on Imagenet dataset\n",
        "  ## include_top = False To exclude the final Fully Connected Layers\n",
        "  \n",
        "  print('##### Create Model #####')\n",
        "  base_model = InceptionV3(input_shape=[image_width, image_height] + [3],weights='imagenet', include_top=False)\n",
        "  \n",
        "  ## Save the inital model setup in base_model_vgg_initial.png file\n",
        "  plot_model(base_model, to_file='base_model_inception_initial.png', show_shapes=True)\n",
        "  \n",
        "  print('##### Add Layers in Model #####')\n",
        "  ## Add bottom layers with output layer specific to the dataset under consideration\n",
        "  model = addAdditionalLayesToBaseModel(base_model, totalClasses)\n",
        "\n",
        "  ## Save the model setup after adding output layers in base_model_vgg_initial.png file\n",
        "  plot_model(model, to_file='base_model_inception_setup.png', show_shapes=True)\n",
        "  \n",
        "  ## Transfer Learning model setup\n",
        "  setupTransferLearn(model, base_model)\n",
        "\n",
        "  print('##### Model Summary #####')\n",
        "  ## Print the Model Summary\n",
        "  model.summary()\n",
        "\n",
        "  ## TensorBoard Integration\n",
        "  log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "  tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
        "  \n",
        "  ## History Object with model Accuracy and Loss values before fine tuning the model\n",
        "  history_1 = model.fit_generator(\n",
        "    train_generator,\n",
        "    epochs=epoch,\n",
        "    steps_per_epoch=totalTrainSamples,\n",
        "    validation_data=validation_generator,\n",
        "    validation_steps=totalTestSamples,\n",
        "    callbacks=[tensorboard_callback])\n",
        "  \n",
        "  print('##### Plot Train and Validation Set - Accuracy and Loss Values Before Tuning #####')\n",
        "  #plot_training(history_1)\n",
        "\n",
        "  # Fine Tune the Model by changing the Layer Trainable property\n",
        "  changeLayerPropertyForFineTune(model)\n",
        "  \n",
        "  ## History Object with model Accuracy and Loss values After fine tuning the model\n",
        "  history_2 = model.fit_generator(\n",
        "    train_generator,\n",
        "    steps_per_epoch=totalTrainSamples,\n",
        "    epochs=epoch,\n",
        "    validation_data=validation_generator,\n",
        "    validation_steps=totalTestSamples,\n",
        "    callbacks=[tensorboard_callback])\n",
        "  \n",
        "  print('##### Plot Train and Validation Set - Accuracy and Loss Values After Tuning #####')\n",
        "  #plot_training(history_2)\n",
        "\n",
        "  model.save('inception.h5')\n",
        "  ## Getting the file names from the validation set to get sample misclassified images\n",
        "  fnames = validation_generator.filenames\n",
        "\n",
        "  ## Actual classes\n",
        "  actualClass = validation_generator.classes\n",
        "  print('##### Actual Class #####', actualClass)\n",
        "\n",
        "  ## Converting the Labels to Indices\n",
        "  label2index = validation_generator.class_indices\n",
        "  idx2label = dict((v,k) for k,v in label2index.items())\n",
        "\n",
        "  ## To get the model Predictions based on Validation set\n",
        "  predictions= model.predict_generator(validation_generator, steps = validation_generator.samples/validation_generator.batch_size, verbose=0)\n",
        "\n",
        "  ## Predictions are in Float, Rounding them to get the actual classes\n",
        "  predicted_classes = np.argmax(predictions,axis=1)\n",
        "  ## print(predicted_classes)\n",
        "\n",
        "  print('##### Some Misclassified classes #####')\n",
        "  errors = np.where(predicted_classes != actualClass)[0]\n",
        "  print(\"No of errors = {}/{}\".format(len(errors),validation_generator.samples))\n",
        "\n",
        "  # for i in range(5):\n",
        "  #   pred_class = np.argmax(predictions[errors[i]])\n",
        "  #   pred_label = idx2label[pred_class]\n",
        "  #   title = 'Original label:{}, Prediction :{}, confidence : {:.3f}'.format(fnames[errors[i]].split('/')[0], pred_label, predictions[errors[i]][pred_class])\n",
        "  #   original = load_img('{}/{}'.format(test_path,fnames[errors[i]]))\n",
        "  #   plt.figure(figsize=[7,7])\n",
        "  #   plt.axis('off')\n",
        "  #   plt.title(title)\n",
        "  #   plt.imshow(original)\n",
        "  #   plt.show()\n",
        "\n",
        "  print('##### Class mapping to the Index #####')\n",
        "  print(idx2label)\n",
        "\n",
        "  print('##### Plotting Confusion Matrix #####')\n",
        "  results = confusion_matrix(actualClass, predicted_classes) \n",
        "  #print(results)\n",
        "\n",
        "  sns.set(font_scale=1.4) # for label size\n",
        "  sns.heatmap(results, annot=True)\n",
        "  plt.figure(figsize=(5,5))\n",
        "  plt.show()\n",
        "\n",
        "  print('##### Accuracy Score #####')\n",
        "  print(accuracy_score(actualClass, predicted_classes))\n",
        "\n",
        "  print('##### classification_report #####')\n",
        "  print(classification_report(actualClass, predicted_classes))\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j_YT_ihGx35H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_training(history):\n",
        "  accuracy = history.history['accuracy']\n",
        "  val_accuracy = history.history['val_accuracy']\n",
        "  loss = history.history['loss']\n",
        "  val_loss = history.history['val_loss']\n",
        "  epochs = range(len(accuracy))\n",
        "\n",
        "  plt.plot(epochs, accuracy)\n",
        "  plt.plot(epochs, val_accuracy, color='b')\n",
        "  plt.title('Training and validation accuracy')\n",
        "  plt.figure()\n",
        "\n",
        "  plt.plot(epochs, loss)\n",
        "  plt.plot(epochs, val_loss, color='b')\n",
        "  plt.title('Training and validation loss')\n",
        "  plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8zVkX9S2x30l",
        "colab_type": "code",
        "outputId": "7a28c9b9-da88-4b42-c38b-0f4f257c2615",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "## To create and run the model in the specified device\n",
        "with strategy.scope():\n",
        "  transferLearningModel()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "##### Transfer Learning model to train on Yoga Dataset #####\n",
            "##### Getting the file Count #####\n",
            "##### Getting the file Count #####\n",
            "##### Data Augmentation #####\n",
            "Found 917 images belonging to 3 classes.\n",
            "Found 131 images belonging to 3 classes.\n",
            "##### Create Model #####\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_v3/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "87916544/87910968 [==============================] - 1s 0us/step\n",
            "##### Add Layers in Model #####\n",
            "##### Adding layers to the base model #####\n",
            "##### Setting up the Transfer learning Model #####\n",
            "##### Model Summary #####\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 299, 299, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d (Conv2D)                 (None, 149, 149, 32) 864         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization (BatchNorma (None, 149, 149, 32) 96          conv2d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 149, 149, 32) 0           batch_normalization[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 147, 147, 32) 9216        activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 147, 147, 32) 96          conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 147, 147, 32) 0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 147, 147, 64) 18432       activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 147, 147, 64) 192         conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 147, 147, 64) 0           batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D)    (None, 73, 73, 64)   0           activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 73, 73, 80)   5120        max_pooling2d[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 73, 73, 80)   240         conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 73, 73, 80)   0           batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 71, 71, 192)  138240      activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 71, 71, 192)  576         conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 71, 71, 192)  0           batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 35, 35, 192)  0           activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 35, 35, 64)   12288       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, 35, 35, 64)   192         conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 35, 35, 64)   0           batch_normalization_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 35, 35, 48)   9216        max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 35, 35, 96)   55296       activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 35, 35, 48)   144         conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, 35, 35, 96)   288         conv2d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 35, 35, 48)   0           batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 35, 35, 96)   0           batch_normalization_9[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d (AveragePooli (None, 35, 35, 192)  0           max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 35, 35, 64)   12288       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 35, 35, 64)   76800       activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, 35, 35, 96)   82944       activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, 35, 35, 32)   6144        average_pooling2d[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 35, 35, 64)   192         conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, 35, 35, 64)   192         conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_10 (BatchNo (None, 35, 35, 96)   288         conv2d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_11 (BatchNo (None, 35, 35, 32)   96          conv2d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 35, 35, 64)   0           batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 35, 35, 64)   0           batch_normalization_7[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 35, 35, 96)   0           batch_normalization_10[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 35, 35, 32)   0           batch_normalization_11[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed0 (Concatenate)            (None, 35, 35, 256)  0           activation_5[0][0]               \n",
            "                                                                 activation_7[0][0]               \n",
            "                                                                 activation_10[0][0]              \n",
            "                                                                 activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_15 (Conv2D)              (None, 35, 35, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_15 (BatchNo (None, 35, 35, 64)   192         conv2d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 35, 35, 64)   0           batch_normalization_15[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_13 (Conv2D)              (None, 35, 35, 48)   12288       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_16 (Conv2D)              (None, 35, 35, 96)   55296       activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_13 (BatchNo (None, 35, 35, 48)   144         conv2d_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_16 (BatchNo (None, 35, 35, 96)   288         conv2d_16[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 35, 35, 48)   0           batch_normalization_13[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 35, 35, 96)   0           batch_normalization_16[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_1 (AveragePoo (None, 35, 35, 256)  0           mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, 35, 35, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_14 (Conv2D)              (None, 35, 35, 64)   76800       activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_17 (Conv2D)              (None, 35, 35, 96)   82944       activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_18 (Conv2D)              (None, 35, 35, 64)   16384       average_pooling2d_1[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_12 (BatchNo (None, 35, 35, 64)   192         conv2d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_14 (BatchNo (None, 35, 35, 64)   192         conv2d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_17 (BatchNo (None, 35, 35, 96)   288         conv2d_17[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_18 (BatchNo (None, 35, 35, 64)   192         conv2d_18[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 35, 35, 64)   0           batch_normalization_12[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 35, 35, 64)   0           batch_normalization_14[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 35, 35, 96)   0           batch_normalization_17[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 35, 35, 64)   0           batch_normalization_18[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed1 (Concatenate)            (None, 35, 35, 288)  0           activation_12[0][0]              \n",
            "                                                                 activation_14[0][0]              \n",
            "                                                                 activation_17[0][0]              \n",
            "                                                                 activation_18[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_22 (Conv2D)              (None, 35, 35, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_22 (BatchNo (None, 35, 35, 64)   192         conv2d_22[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_22 (Activation)      (None, 35, 35, 64)   0           batch_normalization_22[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_20 (Conv2D)              (None, 35, 35, 48)   13824       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_23 (Conv2D)              (None, 35, 35, 96)   55296       activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_20 (BatchNo (None, 35, 35, 48)   144         conv2d_20[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_23 (BatchNo (None, 35, 35, 96)   288         conv2d_23[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_20 (Activation)      (None, 35, 35, 48)   0           batch_normalization_20[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_23 (Activation)      (None, 35, 35, 96)   0           batch_normalization_23[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_2 (AveragePoo (None, 35, 35, 288)  0           mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_19 (Conv2D)              (None, 35, 35, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_21 (Conv2D)              (None, 35, 35, 64)   76800       activation_20[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_24 (Conv2D)              (None, 35, 35, 96)   82944       activation_23[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_25 (Conv2D)              (None, 35, 35, 64)   18432       average_pooling2d_2[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_19 (BatchNo (None, 35, 35, 64)   192         conv2d_19[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_21 (BatchNo (None, 35, 35, 64)   192         conv2d_21[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_24 (BatchNo (None, 35, 35, 96)   288         conv2d_24[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_25 (BatchNo (None, 35, 35, 64)   192         conv2d_25[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_19 (Activation)      (None, 35, 35, 64)   0           batch_normalization_19[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_21 (Activation)      (None, 35, 35, 64)   0           batch_normalization_21[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_24 (Activation)      (None, 35, 35, 96)   0           batch_normalization_24[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_25 (Activation)      (None, 35, 35, 64)   0           batch_normalization_25[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed2 (Concatenate)            (None, 35, 35, 288)  0           activation_19[0][0]              \n",
            "                                                                 activation_21[0][0]              \n",
            "                                                                 activation_24[0][0]              \n",
            "                                                                 activation_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_27 (Conv2D)              (None, 35, 35, 64)   18432       mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_27 (BatchNo (None, 35, 35, 64)   192         conv2d_27[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_27 (Activation)      (None, 35, 35, 64)   0           batch_normalization_27[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_28 (Conv2D)              (None, 35, 35, 96)   55296       activation_27[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_28 (BatchNo (None, 35, 35, 96)   288         conv2d_28[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_28 (Activation)      (None, 35, 35, 96)   0           batch_normalization_28[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_26 (Conv2D)              (None, 17, 17, 384)  995328      mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_29 (Conv2D)              (None, 17, 17, 96)   82944       activation_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_26 (BatchNo (None, 17, 17, 384)  1152        conv2d_26[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_29 (BatchNo (None, 17, 17, 96)   288         conv2d_29[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_26 (Activation)      (None, 17, 17, 384)  0           batch_normalization_26[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_29 (Activation)      (None, 17, 17, 96)   0           batch_normalization_29[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2D)  (None, 17, 17, 288)  0           mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed3 (Concatenate)            (None, 17, 17, 768)  0           activation_26[0][0]              \n",
            "                                                                 activation_29[0][0]              \n",
            "                                                                 max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_34 (Conv2D)              (None, 17, 17, 128)  98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_34 (BatchNo (None, 17, 17, 128)  384         conv2d_34[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_34 (Activation)      (None, 17, 17, 128)  0           batch_normalization_34[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_35 (Conv2D)              (None, 17, 17, 128)  114688      activation_34[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_35 (BatchNo (None, 17, 17, 128)  384         conv2d_35[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_35 (Activation)      (None, 17, 17, 128)  0           batch_normalization_35[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_31 (Conv2D)              (None, 17, 17, 128)  98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_36 (Conv2D)              (None, 17, 17, 128)  114688      activation_35[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_31 (BatchNo (None, 17, 17, 128)  384         conv2d_31[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_36 (BatchNo (None, 17, 17, 128)  384         conv2d_36[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_31 (Activation)      (None, 17, 17, 128)  0           batch_normalization_31[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_36 (Activation)      (None, 17, 17, 128)  0           batch_normalization_36[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_32 (Conv2D)              (None, 17, 17, 128)  114688      activation_31[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_37 (Conv2D)              (None, 17, 17, 128)  114688      activation_36[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_32 (BatchNo (None, 17, 17, 128)  384         conv2d_32[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_37 (BatchNo (None, 17, 17, 128)  384         conv2d_37[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_32 (Activation)      (None, 17, 17, 128)  0           batch_normalization_32[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_37 (Activation)      (None, 17, 17, 128)  0           batch_normalization_37[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_3 (AveragePoo (None, 17, 17, 768)  0           mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_30 (Conv2D)              (None, 17, 17, 192)  147456      mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_33 (Conv2D)              (None, 17, 17, 192)  172032      activation_32[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_38 (Conv2D)              (None, 17, 17, 192)  172032      activation_37[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_39 (Conv2D)              (None, 17, 17, 192)  147456      average_pooling2d_3[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_30 (BatchNo (None, 17, 17, 192)  576         conv2d_30[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_33 (BatchNo (None, 17, 17, 192)  576         conv2d_33[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_38 (BatchNo (None, 17, 17, 192)  576         conv2d_38[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_39 (BatchNo (None, 17, 17, 192)  576         conv2d_39[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_30 (Activation)      (None, 17, 17, 192)  0           batch_normalization_30[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_33 (Activation)      (None, 17, 17, 192)  0           batch_normalization_33[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_38 (Activation)      (None, 17, 17, 192)  0           batch_normalization_38[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_39 (Activation)      (None, 17, 17, 192)  0           batch_normalization_39[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed4 (Concatenate)            (None, 17, 17, 768)  0           activation_30[0][0]              \n",
            "                                                                 activation_33[0][0]              \n",
            "                                                                 activation_38[0][0]              \n",
            "                                                                 activation_39[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_44 (Conv2D)              (None, 17, 17, 160)  122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_44 (BatchNo (None, 17, 17, 160)  480         conv2d_44[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_44 (Activation)      (None, 17, 17, 160)  0           batch_normalization_44[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_45 (Conv2D)              (None, 17, 17, 160)  179200      activation_44[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_45 (BatchNo (None, 17, 17, 160)  480         conv2d_45[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_45 (Activation)      (None, 17, 17, 160)  0           batch_normalization_45[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_41 (Conv2D)              (None, 17, 17, 160)  122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_46 (Conv2D)              (None, 17, 17, 160)  179200      activation_45[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_41 (BatchNo (None, 17, 17, 160)  480         conv2d_41[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_46 (BatchNo (None, 17, 17, 160)  480         conv2d_46[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_41 (Activation)      (None, 17, 17, 160)  0           batch_normalization_41[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_46 (Activation)      (None, 17, 17, 160)  0           batch_normalization_46[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_42 (Conv2D)              (None, 17, 17, 160)  179200      activation_41[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_47 (Conv2D)              (None, 17, 17, 160)  179200      activation_46[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_42 (BatchNo (None, 17, 17, 160)  480         conv2d_42[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_47 (BatchNo (None, 17, 17, 160)  480         conv2d_47[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_42 (Activation)      (None, 17, 17, 160)  0           batch_normalization_42[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_47 (Activation)      (None, 17, 17, 160)  0           batch_normalization_47[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_4 (AveragePoo (None, 17, 17, 768)  0           mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_40 (Conv2D)              (None, 17, 17, 192)  147456      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_43 (Conv2D)              (None, 17, 17, 192)  215040      activation_42[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_48 (Conv2D)              (None, 17, 17, 192)  215040      activation_47[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_49 (Conv2D)              (None, 17, 17, 192)  147456      average_pooling2d_4[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_40 (BatchNo (None, 17, 17, 192)  576         conv2d_40[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_43 (BatchNo (None, 17, 17, 192)  576         conv2d_43[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_48 (BatchNo (None, 17, 17, 192)  576         conv2d_48[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_49 (BatchNo (None, 17, 17, 192)  576         conv2d_49[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_40 (Activation)      (None, 17, 17, 192)  0           batch_normalization_40[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_43 (Activation)      (None, 17, 17, 192)  0           batch_normalization_43[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_48 (Activation)      (None, 17, 17, 192)  0           batch_normalization_48[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_49 (Activation)      (None, 17, 17, 192)  0           batch_normalization_49[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed5 (Concatenate)            (None, 17, 17, 768)  0           activation_40[0][0]              \n",
            "                                                                 activation_43[0][0]              \n",
            "                                                                 activation_48[0][0]              \n",
            "                                                                 activation_49[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_54 (Conv2D)              (None, 17, 17, 160)  122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_54 (BatchNo (None, 17, 17, 160)  480         conv2d_54[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_54 (Activation)      (None, 17, 17, 160)  0           batch_normalization_54[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_55 (Conv2D)              (None, 17, 17, 160)  179200      activation_54[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_55 (BatchNo (None, 17, 17, 160)  480         conv2d_55[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_55 (Activation)      (None, 17, 17, 160)  0           batch_normalization_55[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_51 (Conv2D)              (None, 17, 17, 160)  122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_56 (Conv2D)              (None, 17, 17, 160)  179200      activation_55[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_51 (BatchNo (None, 17, 17, 160)  480         conv2d_51[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_56 (BatchNo (None, 17, 17, 160)  480         conv2d_56[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_51 (Activation)      (None, 17, 17, 160)  0           batch_normalization_51[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_56 (Activation)      (None, 17, 17, 160)  0           batch_normalization_56[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_52 (Conv2D)              (None, 17, 17, 160)  179200      activation_51[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_57 (Conv2D)              (None, 17, 17, 160)  179200      activation_56[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_52 (BatchNo (None, 17, 17, 160)  480         conv2d_52[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_57 (BatchNo (None, 17, 17, 160)  480         conv2d_57[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_52 (Activation)      (None, 17, 17, 160)  0           batch_normalization_52[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_57 (Activation)      (None, 17, 17, 160)  0           batch_normalization_57[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_5 (AveragePoo (None, 17, 17, 768)  0           mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_50 (Conv2D)              (None, 17, 17, 192)  147456      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_53 (Conv2D)              (None, 17, 17, 192)  215040      activation_52[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_58 (Conv2D)              (None, 17, 17, 192)  215040      activation_57[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_59 (Conv2D)              (None, 17, 17, 192)  147456      average_pooling2d_5[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_50 (BatchNo (None, 17, 17, 192)  576         conv2d_50[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_53 (BatchNo (None, 17, 17, 192)  576         conv2d_53[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_58 (BatchNo (None, 17, 17, 192)  576         conv2d_58[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_59 (BatchNo (None, 17, 17, 192)  576         conv2d_59[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_50 (Activation)      (None, 17, 17, 192)  0           batch_normalization_50[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_53 (Activation)      (None, 17, 17, 192)  0           batch_normalization_53[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_58 (Activation)      (None, 17, 17, 192)  0           batch_normalization_58[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_59 (Activation)      (None, 17, 17, 192)  0           batch_normalization_59[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed6 (Concatenate)            (None, 17, 17, 768)  0           activation_50[0][0]              \n",
            "                                                                 activation_53[0][0]              \n",
            "                                                                 activation_58[0][0]              \n",
            "                                                                 activation_59[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_64 (Conv2D)              (None, 17, 17, 192)  147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_64 (BatchNo (None, 17, 17, 192)  576         conv2d_64[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_64 (Activation)      (None, 17, 17, 192)  0           batch_normalization_64[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_65 (Conv2D)              (None, 17, 17, 192)  258048      activation_64[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_65 (BatchNo (None, 17, 17, 192)  576         conv2d_65[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_65 (Activation)      (None, 17, 17, 192)  0           batch_normalization_65[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_61 (Conv2D)              (None, 17, 17, 192)  147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_66 (Conv2D)              (None, 17, 17, 192)  258048      activation_65[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_61 (BatchNo (None, 17, 17, 192)  576         conv2d_61[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_66 (BatchNo (None, 17, 17, 192)  576         conv2d_66[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_61 (Activation)      (None, 17, 17, 192)  0           batch_normalization_61[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_66 (Activation)      (None, 17, 17, 192)  0           batch_normalization_66[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_62 (Conv2D)              (None, 17, 17, 192)  258048      activation_61[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_67 (Conv2D)              (None, 17, 17, 192)  258048      activation_66[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_62 (BatchNo (None, 17, 17, 192)  576         conv2d_62[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_67 (BatchNo (None, 17, 17, 192)  576         conv2d_67[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_62 (Activation)      (None, 17, 17, 192)  0           batch_normalization_62[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_67 (Activation)      (None, 17, 17, 192)  0           batch_normalization_67[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_6 (AveragePoo (None, 17, 17, 768)  0           mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_60 (Conv2D)              (None, 17, 17, 192)  147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_63 (Conv2D)              (None, 17, 17, 192)  258048      activation_62[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_68 (Conv2D)              (None, 17, 17, 192)  258048      activation_67[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_69 (Conv2D)              (None, 17, 17, 192)  147456      average_pooling2d_6[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_60 (BatchNo (None, 17, 17, 192)  576         conv2d_60[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_63 (BatchNo (None, 17, 17, 192)  576         conv2d_63[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_68 (BatchNo (None, 17, 17, 192)  576         conv2d_68[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_69 (BatchNo (None, 17, 17, 192)  576         conv2d_69[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_60 (Activation)      (None, 17, 17, 192)  0           batch_normalization_60[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_63 (Activation)      (None, 17, 17, 192)  0           batch_normalization_63[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_68 (Activation)      (None, 17, 17, 192)  0           batch_normalization_68[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_69 (Activation)      (None, 17, 17, 192)  0           batch_normalization_69[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed7 (Concatenate)            (None, 17, 17, 768)  0           activation_60[0][0]              \n",
            "                                                                 activation_63[0][0]              \n",
            "                                                                 activation_68[0][0]              \n",
            "                                                                 activation_69[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_72 (Conv2D)              (None, 17, 17, 192)  147456      mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_72 (BatchNo (None, 17, 17, 192)  576         conv2d_72[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_72 (Activation)      (None, 17, 17, 192)  0           batch_normalization_72[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_73 (Conv2D)              (None, 17, 17, 192)  258048      activation_72[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_73 (BatchNo (None, 17, 17, 192)  576         conv2d_73[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_73 (Activation)      (None, 17, 17, 192)  0           batch_normalization_73[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_70 (Conv2D)              (None, 17, 17, 192)  147456      mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_74 (Conv2D)              (None, 17, 17, 192)  258048      activation_73[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_70 (BatchNo (None, 17, 17, 192)  576         conv2d_70[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_74 (BatchNo (None, 17, 17, 192)  576         conv2d_74[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_70 (Activation)      (None, 17, 17, 192)  0           batch_normalization_70[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_74 (Activation)      (None, 17, 17, 192)  0           batch_normalization_74[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_71 (Conv2D)              (None, 8, 8, 320)    552960      activation_70[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_75 (Conv2D)              (None, 8, 8, 192)    331776      activation_74[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_71 (BatchNo (None, 8, 8, 320)    960         conv2d_71[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_75 (BatchNo (None, 8, 8, 192)    576         conv2d_75[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_71 (Activation)      (None, 8, 8, 320)    0           batch_normalization_71[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_75 (Activation)      (None, 8, 8, 192)    0           batch_normalization_75[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2D)  (None, 8, 8, 768)    0           mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed8 (Concatenate)            (None, 8, 8, 1280)   0           activation_71[0][0]              \n",
            "                                                                 activation_75[0][0]              \n",
            "                                                                 max_pooling2d_3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_80 (Conv2D)              (None, 8, 8, 448)    573440      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_80 (BatchNo (None, 8, 8, 448)    1344        conv2d_80[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_80 (Activation)      (None, 8, 8, 448)    0           batch_normalization_80[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_77 (Conv2D)              (None, 8, 8, 384)    491520      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_81 (Conv2D)              (None, 8, 8, 384)    1548288     activation_80[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_77 (BatchNo (None, 8, 8, 384)    1152        conv2d_77[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_81 (BatchNo (None, 8, 8, 384)    1152        conv2d_81[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_77 (Activation)      (None, 8, 8, 384)    0           batch_normalization_77[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_81 (Activation)      (None, 8, 8, 384)    0           batch_normalization_81[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_78 (Conv2D)              (None, 8, 8, 384)    442368      activation_77[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_79 (Conv2D)              (None, 8, 8, 384)    442368      activation_77[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_82 (Conv2D)              (None, 8, 8, 384)    442368      activation_81[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_83 (Conv2D)              (None, 8, 8, 384)    442368      activation_81[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_7 (AveragePoo (None, 8, 8, 1280)   0           mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_76 (Conv2D)              (None, 8, 8, 320)    409600      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_78 (BatchNo (None, 8, 8, 384)    1152        conv2d_78[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_79 (BatchNo (None, 8, 8, 384)    1152        conv2d_79[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_82 (BatchNo (None, 8, 8, 384)    1152        conv2d_82[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_83 (BatchNo (None, 8, 8, 384)    1152        conv2d_83[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_84 (Conv2D)              (None, 8, 8, 192)    245760      average_pooling2d_7[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_76 (BatchNo (None, 8, 8, 320)    960         conv2d_76[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_78 (Activation)      (None, 8, 8, 384)    0           batch_normalization_78[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_79 (Activation)      (None, 8, 8, 384)    0           batch_normalization_79[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_82 (Activation)      (None, 8, 8, 384)    0           batch_normalization_82[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_83 (Activation)      (None, 8, 8, 384)    0           batch_normalization_83[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_84 (BatchNo (None, 8, 8, 192)    576         conv2d_84[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_76 (Activation)      (None, 8, 8, 320)    0           batch_normalization_76[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed9_0 (Concatenate)          (None, 8, 8, 768)    0           activation_78[0][0]              \n",
            "                                                                 activation_79[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 8, 8, 768)    0           activation_82[0][0]              \n",
            "                                                                 activation_83[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_84 (Activation)      (None, 8, 8, 192)    0           batch_normalization_84[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed9 (Concatenate)            (None, 8, 8, 2048)   0           activation_76[0][0]              \n",
            "                                                                 mixed9_0[0][0]                   \n",
            "                                                                 concatenate[0][0]                \n",
            "                                                                 activation_84[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_89 (Conv2D)              (None, 8, 8, 448)    917504      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_89 (BatchNo (None, 8, 8, 448)    1344        conv2d_89[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_89 (Activation)      (None, 8, 8, 448)    0           batch_normalization_89[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_86 (Conv2D)              (None, 8, 8, 384)    786432      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_90 (Conv2D)              (None, 8, 8, 384)    1548288     activation_89[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_86 (BatchNo (None, 8, 8, 384)    1152        conv2d_86[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_90 (BatchNo (None, 8, 8, 384)    1152        conv2d_90[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_86 (Activation)      (None, 8, 8, 384)    0           batch_normalization_86[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_90 (Activation)      (None, 8, 8, 384)    0           batch_normalization_90[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_87 (Conv2D)              (None, 8, 8, 384)    442368      activation_86[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_88 (Conv2D)              (None, 8, 8, 384)    442368      activation_86[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_91 (Conv2D)              (None, 8, 8, 384)    442368      activation_90[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_92 (Conv2D)              (None, 8, 8, 384)    442368      activation_90[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_8 (AveragePoo (None, 8, 8, 2048)   0           mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_85 (Conv2D)              (None, 8, 8, 320)    655360      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_87 (BatchNo (None, 8, 8, 384)    1152        conv2d_87[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_88 (BatchNo (None, 8, 8, 384)    1152        conv2d_88[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_91 (BatchNo (None, 8, 8, 384)    1152        conv2d_91[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_92 (BatchNo (None, 8, 8, 384)    1152        conv2d_92[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_93 (Conv2D)              (None, 8, 8, 192)    393216      average_pooling2d_8[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_85 (BatchNo (None, 8, 8, 320)    960         conv2d_85[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_87 (Activation)      (None, 8, 8, 384)    0           batch_normalization_87[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_88 (Activation)      (None, 8, 8, 384)    0           batch_normalization_88[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_91 (Activation)      (None, 8, 8, 384)    0           batch_normalization_91[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_92 (Activation)      (None, 8, 8, 384)    0           batch_normalization_92[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_93 (BatchNo (None, 8, 8, 192)    576         conv2d_93[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_85 (Activation)      (None, 8, 8, 320)    0           batch_normalization_85[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed9_1 (Concatenate)          (None, 8, 8, 768)    0           activation_87[0][0]              \n",
            "                                                                 activation_88[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 8, 8, 768)    0           activation_91[0][0]              \n",
            "                                                                 activation_92[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_93 (Activation)      (None, 8, 8, 192)    0           batch_normalization_93[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed10 (Concatenate)           (None, 8, 8, 2048)   0           activation_85[0][0]              \n",
            "                                                                 mixed9_1[0][0]                   \n",
            "                                                                 concatenate_1[0][0]              \n",
            "                                                                 activation_93[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling2d (Globa (None, 2048)         0           mixed10[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 1024)         2098176     global_average_pooling2d[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 3)            3075        dense[0][0]                      \n",
            "==================================================================================================\n",
            "Total params: 23,904,035\n",
            "Trainable params: 2,101,251\n",
            "Non-trainable params: 21,802,784\n",
            "__________________________________________________________________________________________________\n",
            "WARNING:tensorflow:From <ipython-input-29-af2247c17f88>:96: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use Model.fit, which supports generators.\n",
            " 29/917 [..............................] - ETA: 9:40 - loss: 1.3321 - accuracy: 0.4580WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 917 batches). You may need to use the repeat() function when building your dataset.\n",
            "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 131 batches). You may need to use the repeat() function when building your dataset.\n",
            " 29/917 [..............................] - 26s 887ms/step - loss: 1.3321 - accuracy: 0.4580 - val_loss: 1.0502 - val_accuracy: 0.5267\n",
            "##### Plot Train and Validation Set - Accuracy and Loss Values Before Tuning #####\n",
            "##### Freeze/UnFreeze the layers #####\n",
            " 29/917 [..............................] - ETA: 10:07 - loss: 1.3531 - accuracy: 0.4133WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 917 batches). You may need to use the repeat() function when building your dataset.\n",
            "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 131 batches). You may need to use the repeat() function when building your dataset.\n",
            " 29/917 [..............................] - 26s 904ms/step - loss: 1.3531 - accuracy: 0.4133 - val_loss: 1.1503 - val_accuracy: 0.5267\n",
            "##### Plot Train and Validation Set - Accuracy and Loss Values After Tuning #####\n",
            "##### Actual Class ##### [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
            "WARNING:tensorflow:From <ipython-input-29-af2247c17f88>:129: Model.predict_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use Model.predict, which supports generators.\n",
            "##### Some Misclassified classes #####\n",
            "No of errors = 61/131\n",
            "##### Class mapping to the Index #####\n",
            "{0: 'Planks', 1: 'ReversePlanks', 2: 'SidePlanks'}\n",
            "##### Plotting Confusion Matrix #####\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 360x360 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "##### Accuracy Score #####\n",
            "0.5343511450381679\n",
            "##### classification_report #####\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00        29\n",
            "           1       0.53      1.00      0.70        70\n",
            "           2       0.00      0.00      0.00        32\n",
            "\n",
            "    accuracy                           0.53       131\n",
            "   macro avg       0.18      0.33      0.23       131\n",
            "weighted avg       0.29      0.53      0.37       131\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}